{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b357d9-4380-4d22-a0ea-f75ab1f75f79",
   "metadata": {},
   "source": [
    "*Updated for Feb 2026*\n",
    "\n",
    "Thank you for your interest in this work! This is going to be a more technical look at how I classified Jeopardy categories and made the points I made in the article. At this point this code is up to five years old in some parts and may not reflect latest-and-greatest updates in tech.\n",
    "\n",
    "**Category Labeling Process**\n",
    "\n",
    "1. Initial data imports, package imports, and first cleaning steps\n",
    "2. Pre-processing for NLP-based clustering\n",
    "3. Running the clustering\n",
    "4. Consolidating multiple runs of cluster labels\n",
    "5. Linear regression over cluster tags and final labeling\n",
    "6. Data analysis and conclusions used in final article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68dd626-589f-4eef-a45f-ebd1bec6d079",
   "metadata": {},
   "source": [
    "# Initial Setup, Data Imports, Cleaning, Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0dea29-846f-4673-aaa8-bb101f153bc2",
   "metadata": {},
   "source": [
    "**Package import statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7f98348-3bf7-4b09-b964-91f4a854b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I don't need all of these but I don't much feel like spending the time to check all the code to confirm the absence\n",
    "\n",
    "import pandas as pd #dataframe package\n",
    "import os           #for navigating xml library\n",
    "import json         #for navigating json\n",
    "#import ijson        #same\n",
    "from pandas import json_normalize #same\n",
    "import numpy as np  #habit\n",
    "import itertools\n",
    "import random\n",
    "import ast\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import collections\n",
    "import ast\n",
    "import time\n",
    "import re\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LinearRegression, Ridge\n",
    "from itertools import chain\n",
    "\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "from pandasql import sqldf\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a90327-4d2b-4bec-8458-cec0d21b9f91",
   "metadata": {},
   "source": [
    "**Stopwords for NLP**\n",
    "\n",
    "This is a combination of:\n",
    "\n",
    "* A base list of stopwords I found somewhere on the internet, sorry for poor sourcing\n",
    "* Words and phrases like \"Clue Crew\" and \"Jeopardy!\" that interfered with the clustering process\n",
    "* Words and half-words like \"u\" and \"s\" that popped up when I was making flashcards that weren't providing useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99365aa0-28ec-466c-9b14-74b9d05ea898",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = [\"u\", \"s\", \":\", \"this\", \"'s\", \",\", \"'\", \".\", \"i\",\\\n",
    "                  \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\",\\\n",
    "                  \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\",\\\n",
    "                  \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\",\"also\",\\\n",
    "                  \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\",\\\n",
    "                  \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\",\\\n",
    "                  \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\\\n",
    "                  \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\",\\\n",
    "                  \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\\\n",
    "                  \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\",\\\n",
    "                  \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\",\\\n",
    "                  \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\\\n",
    "                  \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\",\\\n",
    "                  \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\",';',\\\n",
    "                  '(',')','1','2','3','4','5','6','7','8','9','10','#','!','&','``',\"''\",'\\\\','wa',\"n't\",\\\n",
    "                  'clue', 'crew', 'jimmy', 'sarah', 'jeopardy', 'jeopardy!', 'nt', 'trebek', \\\n",
    "                  '__', '___', '____', '_____', '______', '_______', '________', '_________', 'blank', 'wa',\\\n",
    "                  'ha', 'one', 'like', 'name', 'called', 'first', '...', '?', \"'re\", \"might\", \"got\", \"said\", #new 2024-25\n",
    "                  \"could\", \"type\", \"made\", \"'ll\", \"'re\", \"'ve\", \"got\", \"get\", \"say\" , \"*\", \\\n",
    "                  'll', 're', 've'] #new 2026\n",
    "\n",
    "\n",
    "tags = ['art'\n",
    ",'business'\n",
    ",'civics'\n",
    ",'classical music'\n",
    ",'fashion'\n",
    ",'film'\n",
    ",'food'\n",
    ",'geography'\n",
    ",'history'\n",
    ",'literature'\n",
    ",'miscellaneous'\n",
    ",'pop culture'\n",
    ",'pop music'\n",
    ",'religion'\n",
    ",'science'\n",
    ",'sports'\n",
    ",'television'\n",
    ",'theater']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733919fd-b811-4969-a850-fc35074b6a3a",
   "metadata": {},
   "source": [
    "**Dataset Imports**\n",
    "\n",
    "Updated version of the clue dataset available here: https://github.com/jwolle1/jeopardy_clue_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b631f52-8bf9-4ed4-8243-e133c3bc7258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\AppData\\Local\\Temp\\ipykernel_48020\\1582720217.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  j = pd.read_csv('combined_season1-41.tsv', sep='\\t', header=0)\n"
     ]
    }
   ],
   "source": [
    "j = pd.read_csv('combined_season1-41.tsv', sep='\\t', header=0)\n",
    "\n",
    "#the j stands for jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f7582-749a-4991-8850-30f914598084",
   "metadata": {},
   "source": [
    "**Lemmatization, Cleaning, Initial Prep**\n",
    "\n",
    "This only needs to be run once and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c8cdf-eba6-4a91-b54e-2266aded43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# episodes 4573 (jun 23 2004) and 6420 (jul 13 2012) contain clues asking to finish the agatha christie novel \"and then there were...\",\n",
    "# which messes up python, this fixes that for now, but row numbers will change in future files so you would need to search by date to make the \n",
    "# fixes below\n",
    "\n",
    "## season 40 file\n",
    "\n",
    "#j.loc[247505, 'question'] = 'None'\n",
    "#j.loc[355714, 'question'] = 'None'\n",
    "\n",
    "## season 41 file\n",
    "\n",
    "j.loc[247676, 'question'] = 'None'\n",
    "j.loc[355885, 'question'] = 'None'\n",
    "\n",
    "# cleaning questions and answers by lemmatizing them, converting them to lowercase, and removing stopwords\n",
    "\n",
    "question_mod = [word_tokenize(item) for item in j.question]\n",
    "\n",
    "question_mod_2 = list()\n",
    "\n",
    "for item in question_mod:\n",
    "    item = [lemmatizer.lemmatize(word) for word in item]\n",
    "    question_mod_2.append(item)\n",
    "    \n",
    "question_mod_3 = list()\n",
    "\n",
    "for item in question_mod_2:\n",
    "    item = [x.lower() for x in item if x.lower() not in stopwords_list]\n",
    "    question_mod_3.append(item)\n",
    "\n",
    "j['question_modified'] = [' '.join(item) for item in question_mod_3]\n",
    "j['question_modified'] = [item.translate(str.maketrans('', '', string.punctuation)) for item in j.question_modified]\n",
    "j['question_modified'] = [item.strip() for item in j.question_modified]\n",
    "\n",
    "answer_mod = [word_tokenize(item) for item in j.answer]\n",
    "\n",
    "answer_mod_2 = list()\n",
    "\n",
    "for item in answer_mod:\n",
    "    item = [lemmatizer.lemmatize(word) for word in item]\n",
    "    answer_mod_2.append(item)\n",
    "    \n",
    "answer_mod_3 = list()\n",
    "\n",
    "for item in answer_mod_2:\n",
    "    item = [x.lower() for x in item if x.lower() not in stopwords_list]\n",
    "    answer_mod_3.append(item)\n",
    "    \n",
    "j['answer_modified'] = answer_mod_3\n",
    "\n",
    "j.to_pickle('s41_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba47ef-f4f6-420a-a300-79a6d84f7826",
   "metadata": {},
   "source": [
    "**Reviewing cleaned output**\n",
    "\n",
    "You can skip here if you've run the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a88b68c-2972-4326-8e08-aa3ca203d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pd.read_pickle('s41_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e8354c-1c72-4e63-8ff7-c45088296c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue_value</th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question_modified</th>\n",
       "      <th>answer_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>481149</th>\n",
       "      <td>200</td>\n",
       "      <td>THE 20th CENTURY</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>princess diana</td>\n",
       "      <td>[death, following, car, crash, pont, de, l'alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481150</th>\n",
       "      <td>400</td>\n",
       "      <td>THE 20th CENTURY</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>decathlon pentathlon</td>\n",
       "      <td>[olympic, game, stockholm, jim, thorpe, won, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481151</th>\n",
       "      <td>800</td>\n",
       "      <td>THE 20th CENTURY</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>operation desert storm</td>\n",
       "      <td>[invasion, kuwait, prompted, allied, operation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481152</th>\n",
       "      <td>1000</td>\n",
       "      <td>THE 20th CENTURY</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>fine gael</td>\n",
       "      <td>[1948, john, costello, became, irish, prime, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481153</th>\n",
       "      <td>200</td>\n",
       "      <td>IT'S A NATIONAL THING</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>chinese checker</td>\n",
       "      <td>[deriving, game, halma—greek, jump, —this, boa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        clue_value               category    air_date       question_modified  \\\n",
       "481149         200       THE 20th CENTURY  2022-02-03          princess diana   \n",
       "481150         400       THE 20th CENTURY  2022-02-03    decathlon pentathlon   \n",
       "481151         800       THE 20th CENTURY  2022-02-03  operation desert storm   \n",
       "481152        1000       THE 20th CENTURY  2022-02-03               fine gael   \n",
       "481153         200  IT'S A NATIONAL THING  2022-02-03         chinese checker   \n",
       "\n",
       "                                          answer_modified  \n",
       "481149  [death, following, car, crash, pont, de, l'alm...  \n",
       "481150  [olympic, game, stockholm, jim, thorpe, won, g...  \n",
       "481151  [invasion, kuwait, prompted, allied, operation...  \n",
       "481152  [1948, john, costello, became, irish, prime, m...  \n",
       "481153  [deriving, game, halma—greek, jump, —this, boa...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current output\n",
    "\n",
    "j[j.air_date == '2022-02-03'][['clue_value', 'category', 'air_date', 'question_modified', 'answer_modified']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de57e9c-7f70-40ba-8393-cbfcea83e7f0",
   "metadata": {},
   "source": [
    "# Preparing the Categories for Clustering by Content\n",
    "\n",
    "With code lifted and adapted from: https://avidml.wordpress.com/2016/10/18/sample-code-to-cluster-unstructured-text/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48bac4e1-abbd-40f2-91de-ed59ed841e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_comma_list(string):\n",
    "    li = list(string.split(\" \"))\n",
    "    return li\n",
    "\n",
    "def combine_lists(list1, list2):\n",
    "    lis = list1 + list2\n",
    "    return(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "736eb186-fc34-4d33-8e43-c08ba4402237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripping question, category and answer text down to a list of the non-stopwords used in the clues\n",
    "# variables are the presence or absence of a word; i do not weight for multiple uses of a word\n",
    "\n",
    "j['question_modified'] = [str(i) for i in j.question_modified]\n",
    "j['question_list'] = [to_comma_list(i) for i in j.question_modified]\n",
    "\n",
    "j['answer_list'] = [[k.strip() for k in i] for i in j.answer_modified]\n",
    "\n",
    "j['cat_list'] = [to_comma_list(i.lower()) for i in j.category]\n",
    "j['cat_list'] = [[lemmatizer.lemmatize(word) for word in lis] for lis in j.cat_list]\n",
    "\n",
    "j['all_term_list'] = j['question_list'] + j['answer_list'] + j['cat_list']\n",
    "j['all_term_list'] = [[i for i in x if i not in stopwords_list] for x in j.all_term_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168561ea-7d43-407e-a1b9-1f7f5523872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round: 1\n",
      "clue_value: 400\n",
      "daily_double_value: 0\n",
      "category: 4-LETTER GEOGRAPHY\n",
      "comments: nan\n",
      "answer: A natural history museum, the Koenig is in this city, once the capital of West Germany\n",
      "question: Bonn\n",
      "air_date: 2022-02-01\n",
      "notes: nan\n",
      "question_modified: bonn\n",
      "answer_modified: ['natural', 'history', 'museum', 'koenig', 'city', 'capital', 'west', 'germany']\n",
      "question_list: ['bonn']\n",
      "answer_list: ['natural', 'history', 'museum', 'koenig', 'city', 'capital', 'west', 'germany']\n",
      "cat_list: ['4-letter', 'geography']\n",
      "all_term_list: ['bonn', 'natural', 'history', 'museum', 'koenig', 'city', 'capital', 'west', 'germany', '4-letter', 'geography']\n"
     ]
    }
   ],
   "source": [
    "# one row of data through this step\n",
    "\n",
    "for i, k in zip(j.columns, j.loc[481047]):\n",
    "    print(str(i) + ': ' + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a76e48e-1b7b-4991-bf3f-d0b2586a9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = j[['category', 'all_term_list']] #the k stands for keopardy\n",
    "for_cats_gp = k.groupby('category', as_index=False).sum()\n",
    "for_cats_gp['all_term_list_deduped'] = [list(set(x)) for x in for_cats_gp.all_term_list] #removes duplicates\n",
    "\n",
    "for_cats_gp['all_term_list2'] = [\" \".join(x) for x in for_cats_gp.all_term_list_deduped]\n",
    "for_cats_gp['len'] = for_cats_gp.all_term_list2.str.len()\n",
    "for_cats_std = for_cats_gp.sort_values('len', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2bab0c5-ce31-49f8-a62a-4d5092f33c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: THE DAY\n",
      " \n",
      "all_term_list: ['april', 'fools', 'day', 'thing', 'reported', 'day', 'flying', 'penguin', 'google', 'translate', 'animal', 'tree', 'grow', 'spaghetti', 'day', 'ihop', '2024', 'restaurant', 'chain', 'partnered', 'feeding', 'america', 'feed', 'america', 'national', 'pancake', 'day', 'day', 'juneteenth', '2022', 'new', 'yorker', 'honored', 'newish', 'federal', 'holiday', 'cover', 'painting', 'black', 'family', '157', 'years', 'day', 'cyber', 'monday', '2005', 'shop.org', 'press', 'release', 'public', 'use', 'term', 'shopping', 'day', 'day', 'thanksgiving', 'day', 'indigenous', 'peoples', 'day', '2021', 'joe', 'biden', 'became', 'u.s.', 'president', 'formally', 'proclaim', 'holiday', 'coincides', 'another', 'fall', 'day']\n",
      " \n",
      "all_term_list_deduped: ['peoples', 'fall', '2024', 'partnered', 'family', 'shop.org', 'term', 'shopping', 'tree', 'penguin', 'america', 'public', 'restaurant', '2021', 'cyber', 'google', 'animal', 'juneteenth', 'yorker', 'monday', 'formally', 'national', 'feeding', 'holiday', 'biden', 'became', 'spaghetti', 'coincides', 'pancake', 'thanksgiving', 'painting', 'u.s.', '2005', 'newish', 'flying', '2022', 'years', 'cover', 'april', 'president', 'black', 'translate', 'use', 'federal', 'day', 'ihop', 'feed', 'new', 'joe', 'fools', 'chain', 'proclaim', '157', 'press', 'honored', 'release', 'another', 'thing', 'grow', 'indigenous', 'reported']\n",
      " \n",
      "all_term_list2: peoples fall 2024 partnered family shop.org term shopping tree penguin america public restaurant 2021 cyber google animal juneteenth yorker monday formally national feeding holiday biden became spaghetti coincides pancake thanksgiving painting u.s. 2005 newish flying 2022 years cover april president black translate use federal day ihop feed new joe fools chain proclaim 157 press honored release another thing grow indigenous reported\n",
      " \n",
      "len: 436\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# example output - \"all term list2\", a list of all key words tied to a category, will become the input for the \n",
    "# category clustering that's coming up in the next step\n",
    "\n",
    "for i, k in zip(for_cats_std.columns, for_cats_std.loc[43196]):\n",
    "    print(str(i) + ': ' + str(k))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df0db1-5911-452b-8525-78548a5b73c9",
   "metadata": {},
   "source": [
    "# Category Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87781f-3ddf-4ccd-b58f-ddb655c20f88",
   "metadata": {},
   "source": [
    "In the current iteration, I ran the below code a handful of times over data through Season 40 (and, when available, 41) with varying numbers of clusters to be created, each time classifying the clusters manually. Each category thus gets at least that many tags. The distribution of the category tags I assigned becomes the dependent variable in a series of linear regressions, one for each broad group, that I run in the next step of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bcb43cb-7f82-4976-a9a7-905f333daba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords_list)\n",
    "tfidf_matrix = vectorizer.fit_transform(for_cats_std['all_term_list2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "653bc774-b1b9-4d01-ae09-45b2c3b3871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num_clusters to be used: 250\n",
      "\n",
      "File_inputDF:\n",
      "                    category  \\\n",
      "34124             POTPOURRI   \n",
      "36949               SCIENCE   \n",
      "25950            LITERATURE   \n",
      "20175               HISTORY   \n",
      "4621       AMERICAN HISTORY   \n",
      "...                     ...   \n",
      "44178       THE LAST \"OUT\\\"   \n",
      "12177              CUBE IT!   \n",
      "44510            THE MONTHS   \n",
      "40721   SYNONYMOUS ANAGRAMS   \n",
      "6336   AUTOS BY THE NUMBERS   \n",
      "\n",
      "                                           all_term_list  \\\n",
      "34124  [foot, location, metatarsal, arch, potpourri, ...   \n",
      "36949  [man, mammal, hold, record, longest, lifespan,...   \n",
      "25950  [tom, depending, book, jones, sawyer, uncle\\, ...   \n",
      "20175  [australia, convicts, british, settler, island...   \n",
      "4621   [sam, houston, served, congressman, state, sen...   \n",
      "...                                                  ...   \n",
      "44178                   [snout, proboscis, last, \"out\\\"]   \n",
      "12177  [, cube, it!, 27, cube, it!, 216, cube, it!, 1...   \n",
      "44510     [march, month, start, day, week, month, month]   \n",
      "40721                    [pat, tap, synonymous, anagram]   \n",
      "6336                         [jaguar, xj6, auto, number]   \n",
      "\n",
      "                                   all_term_list_deduped  \\\n",
      "34124  [, divided, grower, ruth, dividing, semi-block...   \n",
      "36949  [magic, , joule, anywhere\\, divided, nazi-occu...   \n",
      "25950  [, magic, divided, sleep\\, speranza, emile, we...   \n",
      "20175  [, divided, yucatan, hammarskjold, 850, thousa...   \n",
      "4621   [shortest, , divided, document, 1621, conclude...   \n",
      "...                                                  ...   \n",
      "44178                   [\"out\\\", snout, proboscis, last]   \n",
      "12177               [, 1/4, it!, -1, 27, cube, 216, 164]   \n",
      "44510                   [day, march, month, start, week]   \n",
      "40721                    [pat, anagram, synonymous, tap]   \n",
      "6336                         [jaguar, auto, xj6, number]   \n",
      "\n",
      "                                          all_term_list2    len  Cluster_num  \n",
      "34124   divided grower ruth dividing semi-block feath...  47324           67  \n",
      "36949  magic  joule anywhere\\ divided nazi-occupied c...  40582          229  \n",
      "25950   magic divided sleep\\ speranza emile weeping a...  40046          198  \n",
      "20175   divided yucatan hammarskjold 850 thousands ne...  38999           67  \n",
      "4621   shortest  divided document 1621 concluded map ...  36508           67  \n",
      "...                                                  ...    ...          ...  \n",
      "44178                        \"out\\\" snout proboscis last     27          195  \n",
      "12177                         1/4 it! -1 27 cube 216 164     27          195  \n",
      "44510                         day march month start week     26           69  \n",
      "40721                         pat anagram synonymous tap     26          195  \n",
      "6336                              jaguar auto xj6 number     22          195  \n",
      "\n",
      "[56328 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "vector_dict = {}\n",
    "vector_dict = vectorizer.vocabulary_\n",
    "#print(“vector_dict:\\n”, vector_dict)\n",
    "# This is really the header for the tfidf_matrix\n",
    "\n",
    "num_clusters = 250 #i have been doing 250 or 300 clusters usually\n",
    "\n",
    "print ('\\nNum_clusters to be used:', num_clusters)\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, init='k-means++', n_init=5, max_iter=50) #you can turn n_init and max_iter down, they add some serious runtime\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "# Add the cluster number to each comment back to the original DF.\n",
    "clusters = km.labels_.tolist()\n",
    "for_cats_std['Cluster_num'] = clusters\n",
    "\n",
    "#inputDF = inputDF.sort_values([‘Cluster_num’])\n",
    "\n",
    "print('\\nFile_inputDF:\\n', for_cats_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666f599-e91f-4683-a54a-de9a3d56708c",
   "metadata": {},
   "source": [
    "The below code outputs all 250 clusters with the highest-frequency words contained within it for easier analysis. I've omitted that output here, but as an example here is what one cluster looks like when run:\n",
    "\n",
    "246\n",
    "\n",
    "[('emmy', 91), ('won', 80), ('show', 63), ('series', 58), ('best', 45), ('drama', 43), ('comedy', 41), ('tv', 39)]\n",
    "\n",
    "\n",
    "['THE EMMYS', 'ENTERTAINMENT AWARDS', '\\\\\"M\" & EMMYS', 'JULIE & JULIA', 'EMMY-WINNING WOMEN', '& THE EMMY GOES TO...', 'NEVER WON AN EMMY', 'EMMY WINNERS FOR BEST ACTRESS IN A DRAMA', 'EMMY HISTORY', 'POWER AWARDS', '1950s EMMYS', 'THE EMMY AWARDS', 'EMMY-WINNING TELEVISION MOVIES: REAL LIFE EDITION', 'CANADIAN BORN', 'TV \"B\"-RUNS', 'THE MARK TWAIN PRIZE FOR AMERICAN HUMOR', 'EMMY WINNERS', 'EMMY-WINNING GUEST APPEARANCES', '2010 EMMY WINNERS', 'THE GOLDEN AGE OF TELEVISION', 'TERRIFIC TV', 'EMMY TIME', 'DRAMA SERIES WRITING EMMYS', \"TELL THEM WHAT THEY'VE WON, JOHNNY!\", 'EMMYS FOR WRITING', 'THE 2014 EMMYS', 'THE 1955 EMMYS', 'TV ACTORS', 'INITIAL T.V.', 'EMMY M.D.s', 'AN EMMY-WINNING ROLE', 'TELEVISION DRAMA', 'SUPPORTING TV CHARACTERS', 'THE PATRIOT ACT', 'MY TV DADS', 'THE 2011 EMMYS', '1940S TV', 'I WON AN OSCAR, EMMY, TONY & GRAMMY', 'THE 1987 EMMYS', 'CELEBRITY \"M.D.\"s', \"THAT'S SHOW BIZ\", 'COMEDY ON TV', '>', '60 YEARS OF THE EMMYS', 'THE EMMYs', 'THE 1995 EMMY AWARDS', 'SHOW BIZ AWARD WINNERS', 'SAY \"JACK\\\\\"', 'THE 1971 EMMY AWARDS', \"IT'S TV, IT'S HBO\", '1990s EMMYS', 'HER EMMY-WINNING ROLE', 'THE \"X\" GAMES', \"TV's SUPPORTING ACTORS\", \"AND THEN THERE'S BEA ARTHUR\", 'MY NAME IS BARBARA', 'TV IN THE YEAR 2000', 'EMMY FACTS', \"THE ENTERTAINER'S TWITTER BIO\", 'TEEN CHOICE AWARDS 2008', 'EARLY EMMYS', 'OF A MAN NAMED BRADY', '1940s TV', 'PHIL-IBUSTER', 'ENTERTAINMENT FIRSTS', 'THE EMMYS 1967', 'THE 1950 EMMYS', 'EMMY REPEAT WINNERS?', '& THE 21st CENTURY EMMY GOES TO...', 'THE DAYTIME EMMYS', 'THE 1999 EMMY AWARDS', \"\\\\'50s TELEVISION\", 'TV \"P\"EOPLE', '1990 EMMYS', 'A SALUTE TO SALLY FIELD', 'MY EMMY-WINNING ROLE', \"ACTRESSES' EMMYS\", 'SO SAYETH THE TALK SHOW HOST', 'I WON AN EMMY FOR THAT DRAMA', 'THE EMMY FOR...', 'TV DRAMA SERIES', 'THE WINNERS', 'EMMY-WINNING DRAMATIC ACTORS', 'THE 50th ANNUAL EMMY AWARDS', 'TV TALK SHOW HOSTS', 'TV COMEDY CHARACTER NAMES', 'SUPPORTING ACTOR EMMY WINNERS', 'EMMY-WINNING TV', 'TV GUY\"D\\\\\"', 'JESSICA', 'RHYMES WITH TICKLE', 'BEST DRAMA SERIES EMMY AWARDS', 'EMMY: THE WOMEN', 'MARY-LOUISE PARKER', \"EMMY'S BEST DRAMA\", \"THE EMMY WINNER'S SHOW\", '& THE EMMY FOR COMEDY ACTRESS GOES TO...', 'THEY WON EMMYS FOR...', 'THE EMMY AWARDS 1995', 'THE 1988 EMMYS', \"EMMY'S BEST COMEDY SERIES\", \"EMMY'S BEST COMEDY\", 'DAYTIME TV PERSONALITIES', 'ENTERTAINMENT AWARD WINNERS', 'COMEDIC ACTRESSES', 'EMMY: THE MEN', '21st CENTURY EMMYS', \"ENTERTAINERS OF THE '60s\", 'THE 1991 EMMYS', 'EMMYS FOR COMEDY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a845e19-017c-4f37-9d9b-1e3f970295e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,num_clusters):\n",
    "    print(i)\n",
    "    \n",
    "    t = list(for_cats_std[for_cats_std.Cluster_num == i]['all_term_list2'])\n",
    "    pp = [i.split() for i in t]\n",
    "    oo = [item for sublist in pp for item in sublist]\n",
    "    oo = [item for item in oo if item.lower() not in stopwords_list]\n",
    "    counter = collections.Counter(oo)\n",
    "    print(counter.most_common(8))\n",
    "\n",
    "    t = list(for_cats_std[for_cats_std.Cluster_num == i]['category'])\n",
    "    print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cdbf562-0122-4c86-98f7-1afaf339e7fe",
   "metadata": {},
   "source": [
    "I created this set of labels myself for the purposes of studying for Jeopardy, and have redone this several times. Each cluster is assigned up to two labels in a run. Here is how I define each group, with the optional secondary tags I use as applicable - the secondary tags have not been fit to a model yet, but are available in the data:\n",
    "\n",
    "**Art**\n",
    "\n",
    "Questions about painters, works of art, and art museums.\n",
    "* *Secondary tags:* Architecture\n",
    "* *Example categories:* SEE 'EM AT THE MUSEUM, FAMOUS PAINTINGS, ARTISTS' CHOICE\n",
    "\n",
    "**Business**\n",
    "\n",
    "Questions about businesses, the stock market, business leaders, and corporate history.\n",
    "* *Secondary tags:* Transportation (primarily including questions about carmakers and models, as well as some questions about airlines)\n",
    "* *Example categories:* STOCK CARS, MERGERS & ACQUISITIONS, FORTUNE 500 COMPANIES\n",
    "\n",
    "**Civics**\n",
    "\n",
    "Questions about (usually American) government, politics, law, and courts. As could be expected, this often overlaps with history questions.\n",
    "* *Secondary tags:* Politics (questions about current events and elected officials)\n",
    "* *Example categories:* WHAT CABINET DEPARTMENT?, U.S. CONSTITUTION, HISTORIC SUPREME COURT DECISIONS\n",
    "\n",
    "**Classical Music**\n",
    "\n",
    "Questions about symphonies, composers, and musical instruments. This does NOT include questions about opera and ballet, which I elected to put in theater; I am willing to reconsider this and move those to this grouping in a future version.\n",
    "* *Example categories:* YOU'RE NOT ON THE LISZT, THIS ONE TIME AT ORCHESTRA CAMP, GOING FOR BAROQUE\n",
    "  \n",
    "**Fashion**\n",
    "\n",
    "Questions about clothing, designers, and jewelry.\n",
    "* *Example categories:* DESIGNER INITIALS, FASHION FROM HEAD TO TOE, OOTD\n",
    "\n",
    "**Film**\n",
    "\n",
    "Questions about movies, actors, and related awards.\n",
    "* *Example categories:* OSCAR-WINNING DIRECTORS, THE AFI'S 100 GREATEST AMERICAN MOVIES, GENE WILDER\n",
    "\n",
    "**Food**\n",
    "\n",
    "Questions about food, cooking, and beverage, including alcohol.\n",
    "* *Example categories:* INTERNATIONAL CUISINE, WOULD YOU LIKE A COCKTAIL?, GIRL DINNER\n",
    "\n",
    "**Geography**\n",
    "\n",
    "Questions about places, cities, countries, etc. Overlaps with history, as everything that has ever happened has happened in both a time and a place.\n",
    "* *Secondary tags:* Africa, Asia, Canada, Colleges, Europe, Flags, United States\n",
    "* *Example categories:* THE LARGEST IN AREA, ALLITERATION ON THE MAP, TOUGH BODIES OF WATER\n",
    "  \n",
    "**History**\n",
    "\n",
    "Questions about events, world leaders, ancient cultures, etc. Overlaps with geography and civics.\n",
    "* *Secondary tags:* Africa, Canada, Europe, United States, War\n",
    "* *Example categories:* THE BRITISH MONARCH WHEN..., SIGNERS OF THE DECLARATION OF INDEPENDENCE, HISTORIC QUOTATIONS\n",
    "\n",
    "**Literature**\n",
    "\n",
    "Questions about books and authors. Again, not including theater.\n",
    "* *Secondary tags:* Childrens, Poetry\n",
    "* *Example categories:* CLASSIC ENGLISH LIT, PUBLISHED POSTHUMOUSLY, HER FIRST PUBLISHED NOVEL\n",
    "      \n",
    "**Miscellaneous**\n",
    "\n",
    "The everything-else tag, created because this data originate as a prep tool and I do not believe categories like \"10-letter words\" and \"before & after\" can be easily studied, nor did it fit neatly in the study methods I was using. This is also the home for easily-identifiable but rare subgroups, as can be seen in the secondary tags. There are also many grab-bag or loosely themed categories that do not fit easy classification, most obviously including potpourri and hodgepodge categories.\n",
    "* *Secondary tags:* Colors, Holidays, Language (questions involving knowing other languages, such as a Spanish vocabulary or French phrases category), Words (10-LETTER WORDS, answers that share a common word, slang, etc.)\n",
    "* *Example categories:* PEOPLE, ANNUAL EVENTS, ABBREVIATIONS\n",
    "\n",
    "**Pop Culture**\n",
    "\n",
    "Categories in which the questions are about the entertainment world generally but do not easily fit into a specific tag; e.g., \"this is obviously pop culture but not distinctly film, tv, or music.\" Tagging like this still keeps these categories out of the \"miscellaneous\" pool. Also includes less popular media forms like comics and radio. As should be expected, this overlaps heavily with the other pop culture tags. Slowly but surely beginning to include social media and internet culture.\n",
    "* *Secondary tags:* Celebrities\n",
    "* *Example categories:* SCI FI, SHOW BIZ AWARD WINNERS, DOWN THE VIDEO TUBE\n",
    "\n",
    "**Pop Music**\n",
    "\n",
    "Questions about the pop charts, 20th cenutry music, and beyond. Jazz mostly went here.\n",
    "* *Example categories:* ROCK ICONS, BILLBOARD CHART-TOPPERS, NO. 1 ALBUMS OF THE '60s\n",
    "\n",
    "**Religion**\n",
    "\n",
    "Questions about world religions, religious texts, and practices.\n",
    "* *Secondary tags:* Christianity, Mythology\n",
    "* *Example categories:* BIBLICAL QUOTES, GODS & GODDESSES, RELIGIOUS HISTORY\n",
    "\n",
    "**Science**\n",
    "\n",
    "Questions about hard sciences and math.\n",
    "* *Secondary tags:* Animals, Astronomy, Biology, Elements, Math, Medicine, Nature, Plants, Technology\n",
    "* *Example categories:* THE BODY HUMAN, MAMMALS, DID YOU PLANET THAT WAY?\n",
    "  \n",
    "**Sports**\n",
    "\n",
    "Questions about athletes, games, and sports.\n",
    "* *Secondary tags:* Toys and Games\n",
    "* *Example categories:* WE ARE THE CHAMPIONS, BASEBALL ROOKIES OF THE YEAR, NO LONGER AN OLYMPIC SPORT\n",
    "\n",
    "**Television**\n",
    "\n",
    "Questions about tv shows, actors, and related awards.\n",
    "* *Example categories:* EMMY'S BEST DRAMA, IS THERE A TV DOCTOR IN THE HOUSE?, TV CHARACTERS' MAIDEN NAMES\n",
    "\n",
    "**Theater**\n",
    "\n",
    "Questions about things that happen on a stage. As mentioned, this is now the cluster I'm most willing to reconsider/rearrange, as opera and ballet will overlap a fair bit with classical music trivia whereas Broadway is more of a \"pop\" topic.\n",
    "* *Secondary tags:* Ballet, Broadway, Opera, Shakespeare\n",
    "* *Example categories:* SOPRANOS, CHARACTERS IN MUSICALS, AMERICAN BALLET THEATRE'S 75th ANNIVERSARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa1f9630-963f-465f-a650-d265a8c805b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>cat1</th>\n",
       "      <th>sub1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>sub2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>history</td>\n",
       "      <td>history.europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pop culture</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>science</td>\n",
       "      <td>science.animals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>history</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pop music</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>science</td>\n",
       "      <td>science.animals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>television</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster           cat1             sub1           cat2 sub2\n",
       "148      148        history   history.europe            NaN  NaN\n",
       "32        32        science              NaN  miscellaneous  NaN\n",
       "224      224           film              NaN    pop culture  NaN\n",
       "146      146  miscellaneous              NaN            NaN  NaN\n",
       "238      238        science  science.animals            NaN  NaN\n",
       "8          8        history              NaN      pop music  NaN\n",
       "71        71           food              NaN            NaN  NaN\n",
       "2          2        science  science.animals            NaN  NaN\n",
       "38        38     television              NaN            NaN  NaN\n",
       "167      167           food              NaN            NaN  NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_cats_gp = pd.read_csv('cats250_niter5_50_07302025.csv') # previous cluster labels\n",
    "\n",
    "#x = pd.merge(for_cats_gp, for_cats_std, right_on=['Cluster_num'], left_on=['cluster'])\n",
    "#x = x[['category', 'all_term_list_x', 'len', 'Cluster_num']]\n",
    "#x['all_term_list2'] = [\" \".join(x) for x in for_cats_gp.all_term_list]\n",
    "#x.to_csv('cats250_labeled_07302025a.tsv', sep='\\t')\n",
    "\n",
    "# i didn't create labels for the above clusters, but if you do, here's what the labels doc looks like; run the above code to save an iteration\n",
    "\n",
    "for_cats_gp.sample(10) #example of manual labeling doc, which gets merged to clusters and then categories "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab1ba4-9a9c-4bea-942d-3083012ab602",
   "metadata": {},
   "source": [
    "# Consolidating Model Runs\n",
    "\n",
    "Combining all my cluster labeling attempts allows me to give each category a % of times it has been tagged with a particular group. I'm sure there's a more pythonic way to do this. Do not @ me about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bf8cb0b-c54c-4aed-bc54-61a4670c5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cat1</th>\n",
       "      <th>sub1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>sub2</th>\n",
       "      <th>category</th>\n",
       "      <th>all_term_list</th>\n",
       "      <th>all_term_list_deduped</th>\n",
       "      <th>all_term_list2</th>\n",
       "      <th>len</th>\n",
       "      <th>Cluster_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>6856</td>\n",
       "      <td>35</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>miscellaneous.words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WRONG TIME</td>\n",
       "      <td>['tardy', 'latin', 'slow', 'give', 'adjective'...</td>\n",
       "      <td>['refer', 'immature', 'unripe', 'may', 'humor'...</td>\n",
       "      <td>refer immature unripe may humor latin school l...</td>\n",
       "      <td>338</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>6598</td>\n",
       "      <td>33</td>\n",
       "      <td>pop culture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CELEBRITY PALS</td>\n",
       "      <td>['david', 'beckham', 'posh', 'spice', 'said', ...</td>\n",
       "      <td>['frank', 'club', 'jon', 'went', 'plane', 'two...</td>\n",
       "      <td>frank club jon went plane two federer vegas 20...</td>\n",
       "      <td>489</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>3634</td>\n",
       "      <td>16</td>\n",
       "      <td>history</td>\n",
       "      <td>history.united states</td>\n",
       "      <td>civics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THE NEW YORK TIMES NEWS OF 2006</td>\n",
       "      <td>['turin', 'gold', 'hill', 'host', 'city', 'tim...</td>\n",
       "      <td>['tabloids', 'u.s.', 'g.o.p', 'reported', 'sit...</td>\n",
       "      <td>tabloids u.s. g.o.p reported sitting winter ka...</td>\n",
       "      <td>407</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18548</th>\n",
       "      <td>18548</td>\n",
       "      <td>90</td>\n",
       "      <td>science</td>\n",
       "      <td>science.medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCIENTIFIC SOUTH AMERICAN</td>\n",
       "      <td>['malaria', 'manuel', 'patarroyo', 'developed'...</td>\n",
       "      <td>['alzheimer', 'inventing', 'still', 'promoter'...</td>\n",
       "      <td>alzheimer inventing still promoter american he...</td>\n",
       "      <td>451</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32135</th>\n",
       "      <td>32135</td>\n",
       "      <td>138</td>\n",
       "      <td>television</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV ALIENS</td>\n",
       "      <td>['earth', 'passenger', 'battlestar', 'galactic...</td>\n",
       "      <td>['planet', 'galactica', 'hero', 'ralph', 'tv',...</td>\n",
       "      <td>planet galactica hero ralph tv superman greate...</td>\n",
       "      <td>281</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41874</th>\n",
       "      <td>41874</td>\n",
       "      <td>182</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\\"V\" HAVE MAPS</td>\n",
       "      <td>['valley', 'forge', 'prussian', 'baron', 'frie...</td>\n",
       "      <td>['gediminas', 'steuben', 'forge', 'winter', 'm...</td>\n",
       "      <td>gediminas steuben forge winter mang train 19th...</td>\n",
       "      <td>340</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>2449</td>\n",
       "      <td>12</td>\n",
       "      <td>film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BARBRA STREISAND MOVIES</td>\n",
       "      <td>['meet', 'fockers', '2004', 'barbra', 'streisa...</td>\n",
       "      <td>['movie', 'decides', 'ziegfeld', 'funny', 'mee...</td>\n",
       "      <td>movie decides ziegfeld funny meet fockers slum...</td>\n",
       "      <td>265</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16506</th>\n",
       "      <td>16506</td>\n",
       "      <td>75</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>miscellaneous.words</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATTACK OF THE THESAURUS</td>\n",
       "      <td>['fox', 'outsmart', 'outwit', 'someone', 'out-...</td>\n",
       "      <td>['animal', 'out-', 'prevarication', 'ha', 'the...</td>\n",
       "      <td>animal out- prevarication ha thesaurus titan g...</td>\n",
       "      <td>151</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26241</th>\n",
       "      <td>26241</td>\n",
       "      <td>116</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CALIFORNIA EXPORTS</td>\n",
       "      <td>['wines', '90', '%', 'exported', 'u.s.', 'come...</td>\n",
       "      <td>['club', 'u.s.', 'mondavi', '15', 'golf', 'hea...</td>\n",
       "      <td>club u.s. mondavi 15 golf hearing house cochle...</td>\n",
       "      <td>227</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20109</th>\n",
       "      <td>20109</td>\n",
       "      <td>96</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THE OCCULT</td>\n",
       "      <td>['white', 'good', 'magic', 'often', 'referred'...</td>\n",
       "      <td>['female', 'cat', 'ability', 'gazed', 'book', ...</td>\n",
       "      <td>female cat ability gazed book occult practice ...</td>\n",
       "      <td>2648</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  cluster           cat1                   sub1    cat2 sub2  \\\n",
       "6856         6856       35  miscellaneous    miscellaneous.words     NaN  NaN   \n",
       "6598         6598       33    pop culture                    NaN     NaN  NaN   \n",
       "3634         3634       16        history  history.united states  civics  NaN   \n",
       "18548       18548       90        science       science.medicine     NaN  NaN   \n",
       "32135       32135      138     television                    NaN     NaN  NaN   \n",
       "41874       41874      182      geography                    NaN     NaN  NaN   \n",
       "2449         2449       12           film                    NaN     NaN  NaN   \n",
       "16506       16506       75  miscellaneous    miscellaneous.words     NaN  NaN   \n",
       "26241       26241      116  miscellaneous                    NaN     NaN  NaN   \n",
       "20109       20109       96  miscellaneous                    NaN     NaN  NaN   \n",
       "\n",
       "                              category  \\\n",
       "6856                        WRONG TIME   \n",
       "6598                    CELEBRITY PALS   \n",
       "3634   THE NEW YORK TIMES NEWS OF 2006   \n",
       "18548        SCIENTIFIC SOUTH AMERICAN   \n",
       "32135                        TV ALIENS   \n",
       "41874                   \\\"V\" HAVE MAPS   \n",
       "2449           BARBRA STREISAND MOVIES   \n",
       "16506          ATTACK OF THE THESAURUS   \n",
       "26241               CALIFORNIA EXPORTS   \n",
       "20109                       THE OCCULT   \n",
       "\n",
       "                                           all_term_list  \\\n",
       "6856   ['tardy', 'latin', 'slow', 'give', 'adjective'...   \n",
       "6598   ['david', 'beckham', 'posh', 'spice', 'said', ...   \n",
       "3634   ['turin', 'gold', 'hill', 'host', 'city', 'tim...   \n",
       "18548  ['malaria', 'manuel', 'patarroyo', 'developed'...   \n",
       "32135  ['earth', 'passenger', 'battlestar', 'galactic...   \n",
       "41874  ['valley', 'forge', 'prussian', 'baron', 'frie...   \n",
       "2449   ['meet', 'fockers', '2004', 'barbra', 'streisa...   \n",
       "16506  ['fox', 'outsmart', 'outwit', 'someone', 'out-...   \n",
       "26241  ['wines', '90', '%', 'exported', 'u.s.', 'come...   \n",
       "20109  ['white', 'good', 'magic', 'often', 'referred'...   \n",
       "\n",
       "                                   all_term_list_deduped  \\\n",
       "6856   ['refer', 'immature', 'unripe', 'may', 'humor'...   \n",
       "6598   ['frank', 'club', 'jon', 'went', 'plane', 'two...   \n",
       "3634   ['tabloids', 'u.s.', 'g.o.p', 'reported', 'sit...   \n",
       "18548  ['alzheimer', 'inventing', 'still', 'promoter'...   \n",
       "32135  ['planet', 'galactica', 'hero', 'ralph', 'tv',...   \n",
       "41874  ['gediminas', 'steuben', 'forge', 'winter', 'm...   \n",
       "2449   ['movie', 'decides', 'ziegfeld', 'funny', 'mee...   \n",
       "16506  ['animal', 'out-', 'prevarication', 'ha', 'the...   \n",
       "26241  ['club', 'u.s.', 'mondavi', '15', 'golf', 'hea...   \n",
       "20109  ['female', 'cat', 'ability', 'gazed', 'book', ...   \n",
       "\n",
       "                                          all_term_list2   len  Cluster_num  \n",
       "6856   refer immature unripe may humor latin school l...   338           35  \n",
       "6598   frank club jon went plane two federer vegas 20...   489           33  \n",
       "3634   tabloids u.s. g.o.p reported sitting winter ka...   407           16  \n",
       "18548  alzheimer inventing still promoter american he...   451           90  \n",
       "32135  planet galactica hero ralph tv superman greate...   281          138  \n",
       "41874  gediminas steuben forge winter mang train 19th...   340          182  \n",
       "2449   movie decides ziegfeld funny meet fockers slum...   265           12  \n",
       "16506  animal out- prevarication ha thesaurus titan g...   151           75  \n",
       "26241  club u.s. mondavi 15 golf hearing house cochle...   227          116  \n",
       "20109  female cat ability gazed book occult practice ...  2648           96  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('labels/cats_labeled_250_12292024.tsv', sep='\\t').sample(10) #example of label file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adff012a-8edf-4654-8107-9bc504f666f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling in all instances of my labeling from the current regime of labels\n",
    "\n",
    "labels_1 = pd.read_csv('labels/cats_labeled_250_12292024.tsv', sep='\\t')\n",
    "labels_2 = pd.read_csv('labels/cats250_labeled_12302024a.tsv', sep='\\t')\n",
    "labels_3 = pd.read_csv('labels/cats250_labeled_12302024b.tsv', sep='\\t')\n",
    "labels_4 = pd.read_csv('labels/cats250_labeled_12312024a.tsv', sep='\\t')\n",
    "labels_5 = pd.read_csv('labels/cats250_labeled_12312024b.tsv', sep='\\t')\n",
    "labels_6 = pd.read_csv('labels/cats250_labeled_01022025a.tsv', sep='\\t')\n",
    "labels_7 = pd.read_csv('labels/cats250_labeled_01042025a.tsv', sep='\\t')\n",
    "labels_8 = pd.read_csv('labels/cats250_labeled_07272025a.tsv', sep='\\t')\n",
    "labels_9 = pd.read_csv('labels/cats250_labeled_07302025a.tsv', sep='\\t') #includes season 41\n",
    "\n",
    "labels_1 = labels_1[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_2 = labels_2[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_3 = labels_3[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_4 = labels_4[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_5 = labels_5[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_6 = labels_6[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_7 = labels_7[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_8 = labels_8[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "labels_9 = labels_9[['category', 'cat1', 'sub1', 'cat2', 'sub2']]\n",
    "\n",
    "test_merge = pd.merge(labels_1, labels_2, on='category', suffixes=['_a','_b']).fillna('')\n",
    "test_merge = pd.merge(test_merge, labels_3, on='category', suffixes=['','_c']).fillna('')\n",
    "test_merge = pd.merge(test_merge, labels_4, on='category', suffixes=['_c','_d']).fillna('')\n",
    "test_merge = pd.merge(test_merge, labels_5, on='category', suffixes=['_d','_e']).fillna('')\n",
    "test_merge = pd.merge(test_merge, labels_6, on='category', suffixes=['_e','_f']).fillna('')\n",
    "test_merge = pd.merge(test_merge, labels_7, on='category', suffixes=['_f','_g']).fillna('')\n",
    "test_merge = pd.merge(test_merge, labels_8, on='category', suffixes=['_g','_h']).fillna('')\n",
    "test_merge = pd.merge(test_merge, labels_9, on='category', suffixes=['_h','_i'], how='outer').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d660a7b-171f-4497-9dfc-9ea133462588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>cat1_a</th>\n",
       "      <th>sub1_a</th>\n",
       "      <th>cat2_a</th>\n",
       "      <th>sub2_a</th>\n",
       "      <th>cat1_b</th>\n",
       "      <th>sub1_b</th>\n",
       "      <th>cat2_b</th>\n",
       "      <th>sub2_b</th>\n",
       "      <th>cat1_c</th>\n",
       "      <th>...</th>\n",
       "      <th>cat2_g</th>\n",
       "      <th>sub2_g</th>\n",
       "      <th>cat1_h</th>\n",
       "      <th>sub1_h</th>\n",
       "      <th>cat2_h</th>\n",
       "      <th>sub2_h</th>\n",
       "      <th>cat1</th>\n",
       "      <th>sub1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>sub2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75 YEARS OF THE OSCARS</td>\n",
       "      <td>film</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>film</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>film</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>film</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>film</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>miscellaneous.words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>miscellaneous.words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>literature</td>\n",
       "      <td>literature.childrens</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>literature</td>\n",
       "      <td></td>\n",
       "      <td>film</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#1 HITS</td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pop music</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td>theater</td>\n",
       "      <td>theater.broadway</td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#1 SONGS</td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pop music</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pop music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$ IN THE NEWS</td>\n",
       "      <td>civics</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>civics</td>\n",
       "      <td>...</td>\n",
       "      <td>television</td>\n",
       "      <td></td>\n",
       "      <td>film</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  category         cat1_a               sub1_a cat2_a sub2_a  \\\n",
       "0   75 YEARS OF THE OSCARS           film                                      \n",
       "1                        #  miscellaneous  miscellaneous.words                 \n",
       "2                  #1 HITS      pop music                                      \n",
       "3                 #1 SONGS      pop music                                      \n",
       "4            $ IN THE NEWS         civics                                      \n",
       "\n",
       "          cat1_b               sub1_b cat2_b sub2_b         cat1_c  ...  \\\n",
       "0           film                                              film  ...   \n",
       "1  miscellaneous  miscellaneous.words                miscellaneous  ...   \n",
       "2      pop music                                         pop music  ...   \n",
       "3      pop music                                         pop music  ...   \n",
       "4  miscellaneous                                            civics  ...   \n",
       "\n",
       "       cat2_g sub2_g      cat1_h                sub1_h   cat2_h  \\\n",
       "0                           film                                  \n",
       "1                     literature  literature.childrens            \n",
       "2                      pop music                        theater   \n",
       "3                      pop music                                  \n",
       "4  television               film                                  \n",
       "\n",
       "             sub2_h           cat1 sub1  cat2 sub2  \n",
       "0                             film                  \n",
       "1                       literature       film       \n",
       "2  theater.broadway      pop music                  \n",
       "3                        pop music                  \n",
       "4                    miscellaneous                  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2712b98a-6dfe-4e67-bbab-b6372ef2eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of tags for each category\n",
    "\n",
    "cats_all = []\n",
    "subs_all = []\n",
    "\n",
    "for i,j in test_merge.iterrows():\n",
    "    y = [j.cat1_a, j.cat2_a, \n",
    "         j.cat1_b, j.cat2_b, \n",
    "         j.cat1_c, j.cat2_c, \n",
    "         j.cat1_d, j.cat2_d, \n",
    "         j.cat1_e, j.cat2_e,\n",
    "         j.cat1_f, j.cat2_f, \n",
    "         j.cat1_g, j.cat2_g,\n",
    "         j.cat1_h, j.cat2_h,\n",
    "        j.cat1, j.cat2]\n",
    "    #y = list(set(list(filter(None, y)))) #dedupe and remove nulls\n",
    "    y = list(filter(None, y)) # just dedupe\n",
    "    cats_all.append(y)\n",
    "\n",
    "for i,j in test_merge.iterrows():\n",
    "    y = [j.sub1_a, j.sub2_a, \n",
    "         j.sub1_b, j.sub2_b, \n",
    "         j.sub1_c, j.sub2_c, \n",
    "         j.sub1_d, j.sub2_d, \n",
    "         j.sub1_e, j.sub2_e,\n",
    "         j.sub1_f, j.sub2_f, \n",
    "         j.sub1_g, j.sub2_g,\n",
    "         j.sub1_h, j.sub2_h,\n",
    "        j.sub1, j.sub2]\n",
    "    #y = list(set(list(filter(None, y)))) #dedupe and remove nulls\n",
    "    y = list(filter(None, y)) # just dedupe\n",
    "    subs_all.append(y)\n",
    "\n",
    "test_merge['cats'] = cats_all\n",
    "test_merge['cats_len'] = [len(i) for i in test_merge.cats] \n",
    "\n",
    "test_merge['subs'] = subs_all\n",
    "test_merge['subs_len'] = [len(i) for i in test_merge.subs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca7777d-2e49-40d6-a5c0-f2916780f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidating tags into a 0-1 tag label\n",
    "\n",
    "test_merge['tag_count'] = [len(i) for i in test_merge['cats']]\n",
    "test_merge['sub_count'] = [len(i) for i in test_merge['subs']]\n",
    "\n",
    "                              \n",
    "def keep_cat(tag, a_list):\n",
    "    return [i for i in a_list if i == tag]\n",
    "\n",
    "for tag in tags:\n",
    "    test_merge[tag] = [round(len(keep_cat(tag, i)) / j,2) for i, j in zip(test_merge['cats'], test_merge['tag_count'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9fb96-0611-4b7a-a4bc-89829dbfb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the specific case of identifying which sub-population of sports questions is games\n",
    "\n",
    "gametag = []\n",
    "\n",
    "for i, j in zip(test_merge['subs'], test_merge['sub_count']):\n",
    "    try: \n",
    "        val = round(len(keep_cat('sports.toys and games', i)) / j,2)\n",
    "        gametag.append(val)\n",
    "    except:\n",
    "        gametag.append(0)\n",
    "\n",
    "test_merge['games'] = gametag\n",
    "test_merge['games'] = round(test_merge.games * test_merge.sports,2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ddf66d-8699-40fe-9e71-a4eee52a92fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9500</th>\n",
       "      <th>16673</th>\n",
       "      <th>10784</th>\n",
       "      <th>30759</th>\n",
       "      <th>42183</th>\n",
       "      <th>15815</th>\n",
       "      <th>7846</th>\n",
       "      <th>25592</th>\n",
       "      <th>20283</th>\n",
       "      <th>40987</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>CARRYING ON</td>\n",
       "      <td>FOREIGN PHRASEBOOK</td>\n",
       "      <td>CLOSING THE BOOK</td>\n",
       "      <td>NURSERY RHYME THINGS</td>\n",
       "      <td>THE 1970s MUSIC SCENE</td>\n",
       "      <td>FIELD HOCKEY</td>\n",
       "      <td>BLACK'S LAW DICTIONARY SAYS...</td>\n",
       "      <td>LIKE WE DID LAST SUMMER</td>\n",
       "      <td>HIT THE \"BEACH\\\"</td>\n",
       "      <td>TAM O'SHATNER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civics</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classical music</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geography</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ushistory</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>literature</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop culture</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop music</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>television</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theater</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_count</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       9500                16673             10784  \\\n",
       "category         CARRYING ON  FOREIGN PHRASEBOOK  CLOSING THE BOOK   \n",
       "miscellaneous            0.0                 1.0              0.22   \n",
       "art                      0.0                 0.0               0.0   \n",
       "business                 0.0                 0.0               0.0   \n",
       "civics                   0.0                 0.0               0.0   \n",
       "classical music          0.0                 0.0               0.0   \n",
       "fashion                  0.0                 0.0               0.0   \n",
       "film                    0.25                 0.0               0.0   \n",
       "food                     0.0                 0.0               0.0   \n",
       "geography                0.0                 0.0               0.0   \n",
       "history                  0.0                 0.0               0.0   \n",
       "ushistory                0.0                 0.0               0.0   \n",
       "literature               0.0                 0.0              0.78   \n",
       "pop culture             0.33                 0.0               0.0   \n",
       "pop music                0.0                 0.0               0.0   \n",
       "religion                 0.0                 0.0               0.0   \n",
       "science                  0.0                 0.0               0.0   \n",
       "sports                   0.0                 0.0               0.0   \n",
       "television              0.25                 0.0               0.0   \n",
       "theater                 0.17                 0.0               0.0   \n",
       "tag_count                 12                   9                 9   \n",
       "\n",
       "                                30759                  42183         15815  \\\n",
       "category         NURSERY RHYME THINGS  THE 1970s MUSIC SCENE  FIELD HOCKEY   \n",
       "miscellaneous                    0.73                    0.2           0.0   \n",
       "art                               0.0                    0.0           0.0   \n",
       "business                          0.0                    0.0           0.0   \n",
       "civics                            0.0                    0.0           0.0   \n",
       "classical music                   0.0                    0.0           0.0   \n",
       "fashion                           0.0                    0.0           0.0   \n",
       "film                              0.0                    0.1           0.0   \n",
       "food                              0.0                    0.0           0.0   \n",
       "geography                         0.0                    0.3           0.0   \n",
       "history                           0.0                    0.1           0.0   \n",
       "ushistory                         0.0                   0.02           0.0   \n",
       "literature                       0.18                    0.0           0.0   \n",
       "pop culture                       0.0                    0.0           0.0   \n",
       "pop music                         0.0                    0.3           0.0   \n",
       "religion                          0.0                    0.0           0.0   \n",
       "science                          0.09                    0.0           0.0   \n",
       "sports                            0.0                    0.0           1.0   \n",
       "television                        0.0                    0.0           0.0   \n",
       "theater                           0.0                    0.0           0.0   \n",
       "tag_count                          11                     10             9   \n",
       "\n",
       "                                          7846                     25592  \\\n",
       "category         BLACK'S LAW DICTIONARY SAYS...  LIKE WE DID LAST SUMMER   \n",
       "miscellaneous                              0.27                     0.11   \n",
       "art                                         0.0                      0.0   \n",
       "business                                    0.0                      0.0   \n",
       "civics                                     0.55                      0.0   \n",
       "classical music                             0.0                      0.0   \n",
       "fashion                                     0.0                      0.0   \n",
       "film                                        0.0                      0.0   \n",
       "food                                        0.0                      0.0   \n",
       "geography                                   0.0                      0.0   \n",
       "history                                    0.18                     0.67   \n",
       "ushistory                                  0.06                     0.45   \n",
       "literature                                  0.0                      0.0   \n",
       "pop culture                                 0.0                      0.0   \n",
       "pop music                                   0.0                      0.0   \n",
       "religion                                    0.0                      0.0   \n",
       "science                                     0.0                      0.0   \n",
       "sports                                      0.0                      0.0   \n",
       "television                                  0.0                     0.22   \n",
       "theater                                     0.0                      0.0   \n",
       "tag_count                                    11                        9   \n",
       "\n",
       "                            20283          40987  \n",
       "category         HIT THE \"BEACH\\\"  TAM O'SHATNER  \n",
       "miscellaneous                0.18            0.0  \n",
       "art                           0.0            0.0  \n",
       "business                      0.0            0.0  \n",
       "civics                        0.0            0.0  \n",
       "classical music               0.0            0.0  \n",
       "fashion                       0.0            0.0  \n",
       "film                          0.0            0.3  \n",
       "food                          0.0            0.0  \n",
       "geography                    0.36            0.0  \n",
       "history                      0.09            0.0  \n",
       "ushistory                     0.0            0.0  \n",
       "literature                    0.0            0.0  \n",
       "pop culture                   0.0            0.2  \n",
       "pop music                    0.09            0.0  \n",
       "religion                      0.0            0.0  \n",
       "science                       0.0            0.0  \n",
       "sports                       0.27            0.0  \n",
       "television                    0.0            0.5  \n",
       "theater                       0.0            0.0  \n",
       "tag_count                      11             10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge.columns\n",
    "test_merge = test_merge[['category',  'miscellaneous',\n",
    "       'art', 'business', 'civics', 'classical music', 'fashion',\n",
    "       'film', 'food', 'geography', 'history', 'literature',\n",
    "       'pop culture', 'pop music', 'religion', 'science', 'sports', 'television',\n",
    "       'theater', 'tag_count']]\n",
    "\n",
    "test_merge.sample(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9752889-f662-4f30-9ad5-380adbae27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the category data back onto this frame\n",
    "\n",
    "for_cats_std = pd.read_pickle('category_term_lists_s41.pkl')\n",
    "\n",
    "for_cats_std_with_tags = pd.merge(for_cats_std, test_merge, on='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a337893-02a8-4c10-b519-3641cf41bd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>all_term_list</th>\n",
       "      <th>all_term_list_deduped</th>\n",
       "      <th>all_term_list2</th>\n",
       "      <th>len</th>\n",
       "      <th>miscellaneous</th>\n",
       "      <th>art</th>\n",
       "      <th>business</th>\n",
       "      <th>civics</th>\n",
       "      <th>classical music</th>\n",
       "      <th>...</th>\n",
       "      <th>ushistory</th>\n",
       "      <th>literature</th>\n",
       "      <th>pop culture</th>\n",
       "      <th>pop music</th>\n",
       "      <th>religion</th>\n",
       "      <th>science</th>\n",
       "      <th>sports</th>\n",
       "      <th>television</th>\n",
       "      <th>theater</th>\n",
       "      <th>tag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41776</th>\n",
       "      <td>IRON, MAN</td>\n",
       "      <td>[golf, iron, used, sport, may, either, cast, f...</td>\n",
       "      <td>[man, used, element, iron,, protein, necessary...</td>\n",
       "      <td>man used element iron, protein necessary steel...</td>\n",
       "      <td>268</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39473</th>\n",
       "      <td>HOLLYWOOD FRUITS</td>\n",
       "      <td>[grapefruit, cagney, going, shove, omelet, may...</td>\n",
       "      <td>[dream, strawberry, disappeared, humphrey, mut...</td>\n",
       "      <td>dream strawberry disappeared humphrey mutiny\\ ...</td>\n",
       "      <td>281</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26786</th>\n",
       "      <td>RADIO DISNEY TOP 30</td>\n",
       "      <td>[hilary, duff, sept., 2004, top, 30, 11, 13, 1...</td>\n",
       "      <td>[official, lavigne, lindsay, sister, warning, ...</td>\n",
       "      <td>official lavigne lindsay sister warning movie ...</td>\n",
       "      <td>344</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54840</th>\n",
       "      <td>THE WORLD'S PEOPLE</td>\n",
       "      <td>[catholic, 1st, recorded, use, word, applying,...</td>\n",
       "      <td>[1st, billion, use, world's, word, 1.1, around...</td>\n",
       "      <td>1st billion use world's word 1.1 around 100 st...</td>\n",
       "      <td>102</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>STATE CAPITALS</td>\n",
       "      <td>[connecticut, 1875, dual, capital, new, haven,...</td>\n",
       "      <td>[land, 12, wind, 24, 1971, nbc, 30, library, d...</td>\n",
       "      <td>land 12 wind 24 1971 nbc 30 library dakota n s...</td>\n",
       "      <td>14687</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12262</th>\n",
       "      <td>INTERESTING PEOPLE</td>\n",
       "      <td>[home, run, sadaharu, oh, yomiuri, giants, hit...</td>\n",
       "      <td>[organization, fossil, france, dantas, brazili...</td>\n",
       "      <td>organization fossil france dantas brazilian oh...</td>\n",
       "      <td>436</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49453</th>\n",
       "      <td>MOVIE STARS SPEAK</td>\n",
       "      <td>[elijah, wood, admitted, read, lord, rings, ag...</td>\n",
       "      <td>[movie, set, play, read, year, believing, ask,...</td>\n",
       "      <td>movie set play read year believing ask lord mu...</td>\n",
       "      <td>204</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25913</th>\n",
       "      <td>DESCRIBING THE NO. 1 SONG</td>\n",
       "      <td>[vogue, 1990, madonna, turn, magazine, dance, ...</td>\n",
       "      <td>[m, boy, country, enough, baby, grateful, cent...</td>\n",
       "      <td>m boy country enough baby grateful centerfold ...</td>\n",
       "      <td>349</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46627</th>\n",
       "      <td>SPOUSE IN COMMON TO...</td>\n",
       "      <td>[steven, spielberg, amy, irving, kate, capshaw...</td>\n",
       "      <td>[kathryn, michelle, irving, capshaw, spielberg...</td>\n",
       "      <td>kathryn michelle irving capshaw spielberg smit...</td>\n",
       "      <td>232</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46166</th>\n",
       "      <td>RELIGION IN ART</td>\n",
       "      <td>[noah, ark, famous, peaceable, kingdom, series...</td>\n",
       "      <td>[famous, gustav, church, 19th, art, artist, lo...</td>\n",
       "      <td>famous gustav church 19th art artist location ...</td>\n",
       "      <td>236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        category  \\\n",
       "41776                  IRON, MAN   \n",
       "39473           HOLLYWOOD FRUITS   \n",
       "26786        RADIO DISNEY TOP 30   \n",
       "54840         THE WORLD'S PEOPLE   \n",
       "93                STATE CAPITALS   \n",
       "12262         INTERESTING PEOPLE   \n",
       "49453          MOVIE STARS SPEAK   \n",
       "25913  DESCRIBING THE NO. 1 SONG   \n",
       "46627     SPOUSE IN COMMON TO...   \n",
       "46166            RELIGION IN ART   \n",
       "\n",
       "                                           all_term_list  \\\n",
       "41776  [golf, iron, used, sport, may, either, cast, f...   \n",
       "39473  [grapefruit, cagney, going, shove, omelet, may...   \n",
       "26786  [hilary, duff, sept., 2004, top, 30, 11, 13, 1...   \n",
       "54840  [catholic, 1st, recorded, use, word, applying,...   \n",
       "93     [connecticut, 1875, dual, capital, new, haven,...   \n",
       "12262  [home, run, sadaharu, oh, yomiuri, giants, hit...   \n",
       "49453  [elijah, wood, admitted, read, lord, rings, ag...   \n",
       "25913  [vogue, 1990, madonna, turn, magazine, dance, ...   \n",
       "46627  [steven, spielberg, amy, irving, kate, capshaw...   \n",
       "46166  [noah, ark, famous, peaceable, kingdom, series...   \n",
       "\n",
       "                                   all_term_list_deduped  \\\n",
       "41776  [man, used, element, iron,, protein, necessary...   \n",
       "39473  [dream, strawberry, disappeared, humphrey, mut...   \n",
       "26786  [official, lavigne, lindsay, sister, warning, ...   \n",
       "54840  [1st, billion, use, world's, word, 1.1, around...   \n",
       "93     [land, 12, wind, 24, 1971, nbc, 30, library, d...   \n",
       "12262  [organization, fossil, france, dantas, brazili...   \n",
       "49453  [movie, set, play, read, year, believing, ask,...   \n",
       "25913  [m, boy, country, enough, baby, grateful, cent...   \n",
       "46627  [kathryn, michelle, irving, capshaw, spielberg...   \n",
       "46166  [famous, gustav, church, 19th, art, artist, lo...   \n",
       "\n",
       "                                          all_term_list2    len  \\\n",
       "41776  man used element iron, protein necessary steel...    268   \n",
       "39473  dream strawberry disappeared humphrey mutiny\\ ...    281   \n",
       "26786  official lavigne lindsay sister warning movie ...    344   \n",
       "54840  1st billion use world's word 1.1 around 100 st...    102   \n",
       "93     land 12 wind 24 1971 nbc 30 library dakota n s...  14687   \n",
       "12262  organization fossil france dantas brazilian oh...    436   \n",
       "49453  movie set play read year believing ask lord mu...    204   \n",
       "25913  m boy country enough baby grateful centerfold ...    349   \n",
       "46627  kathryn michelle irving capshaw spielberg smit...    232   \n",
       "46166  famous gustav church 19th art artist location ...    236   \n",
       "\n",
       "       miscellaneous   art  business  civics  classical music  ...  ushistory  \\\n",
       "41776           0.11  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "39473           0.18  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "26786           0.00  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "54840           0.09  0.00      0.09     0.0              0.0  ...        0.0   \n",
       "93              0.70  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "12262           0.33  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "49453           0.00  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "25913           0.25  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "46627           0.08  0.00      0.00     0.0              0.0  ...        0.0   \n",
       "46166           0.00  0.78      0.00     0.0              0.0  ...        0.0   \n",
       "\n",
       "       literature  pop culture  pop music  religion  science  sports  \\\n",
       "41776        0.00         0.00       0.00      0.00     0.89     0.0   \n",
       "39473        0.36         0.00       0.00      0.00     0.00     0.0   \n",
       "26786        0.00         0.10       0.60      0.00     0.10     0.1   \n",
       "54840        0.00         0.00       0.00      0.64     0.00     0.0   \n",
       "93           0.00         0.00       0.00      0.00     0.00     0.0   \n",
       "12262        0.00         0.08       0.08      0.00     0.08     0.0   \n",
       "49453        0.10         0.00       0.00      0.00     0.00     0.0   \n",
       "25913        0.00         0.25       0.42      0.00     0.00     0.0   \n",
       "46627        0.00         0.08       0.31      0.00     0.00     0.0   \n",
       "46166        0.00         0.00       0.00      0.11     0.00     0.0   \n",
       "\n",
       "       television  theater  tag_count  \n",
       "41776         0.0     0.00          9  \n",
       "39473         0.0     0.00         11  \n",
       "26786         0.1     0.00         10  \n",
       "54840         0.0     0.00         11  \n",
       "93            0.0     0.00         10  \n",
       "12262         0.0     0.00         12  \n",
       "49453         0.1     0.00         10  \n",
       "25913         0.0     0.08         12  \n",
       "46627         0.0     0.00         13  \n",
       "46166         0.0     0.00          9  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_cats_std_with_tags.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d3394-76b7-420e-8628-32771958b0c9",
   "metadata": {},
   "source": [
    "# Linear Regression on Cluster Tags\n",
    "\n",
    "For each broad genre of topic, I fit a linear regression. Each word's presence or absence is a feature, and the 0-1 value for that tag generated above is the dependent variable. To validate, I output the high-coefficient (\"important\") features for the model, as well as the topics with the strongest predicted value for that model. There's some noise among the list of highest-value features I can't quite iron out, but that doesn't seem to create problems with the outputs.\n",
    "\n",
    "I have not yet created separate models for the secondary tags ('opera' within theater, 'chemistry' within science, etc.) that would make the labels more granular, although those tags are included in the \"labels\" files and do not need any manual labeling from someone else to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c121c04f-90cd-456a-8f51-091d8973fe45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art\n",
      "['vinci', 'painting', 'art', 'magritte', 'whistler', 'gogh', 'painted', 'monet', 'edvard', 'manet', 'matisse', 'wyeth', 'rembrandt', 'painter', 'cather', 'moma', 'rococo', 'guernica', 'dali', 'picasso', 'rodin', 'portrait', 'vermeer', 'heston', 'cubism']\n",
      "['FAMOUS PAINTINGS', \"SEE 'EM AT THE MUSEUM\", \"ARTISTS' CHOICE\", 'PAINTERS', 'FAMOUS PORTRAITS', 'PAINTINGS', 'THE MASTERS', 'FILL IN THE BLANK CANVAS', 'IMPRESSIONISTS', 'PAINTERS & PAINTINGS', 'THE ART WORLD', 'ART \"C\\\\\"', 'ART MOVEMENTS', 'WHERE FOR ART?', 'ARTISTIC QUOTES', 'ARTISTS & THEIR WORKS', 'EUROPEAN PAINTERS', \"I PROBABLY COULDN'T PAINT THAT\", 'YOU GOTTA HAVE ART', '\\\\\"P\"AINTERS & \"P\"AINTING', 'AROUND THE LOUVRE', '\\\\\"R\"T', 'ALL ABOUT ART', 'ARTISTS IN EUROPE', 'MASTERS']\n",
      "business\n",
      "['company', 'stock', 'toyota', 'car', 'pontiac', 'minted', 'airline', 'honda', 'investment', 'buick', 'ferrari', 'paltrow', 'suv', 'mustang', 'volkswagen', 'retailer', 'nasdaq', 'airlines', 'volvo', 'edsel', 'peso', 'business', 'telecom', 'klm', 'exxon']\n",
      "['STOCK CARS', 'NAME THE AUTOMAKER', 'CAR MODELS', 'BUSINESS NEWS 2015', '2001 CARS', 'CARS', \"JAPAN'S NEXT TOP MODEL\", 'YOU AUTO KNOW THE CAR MAKER', '1995 CARS', 'MEETING YOUR CAR MAKER', 'THE COMPANY CAR', 'STOCK: MARKETS', 'HOT WHEELS', 'AUTOMOBILES', '& A NEW CAR!', 'AUTOMOBILE BUSINESS', 'MOTOR TREND CAR OF THE YEAR', 'COMPANY CARS', 'CARS BY THE NUMBER', 'BUSINESS & THE MARKET', 'S.U.V. A-OK', 'WE MAKE THAT VEHICLE', 'I WANT MY SUV', 'MAKE MY CAR', 'NAME THAT CARMAKER']\n",
      "civics\n",
      "['supreme', 'brynner', 'cabinet', 'department', 'amendment', 'bhutto', 'court', 'senate', 'ronald', 'minted', 'affairs', 'reagan', 'treasury', 'immigration', 'iwo', 'unconstitutional', 'speaker', 'republican', 'justice', 'obama', 'senator', 'agency', 'bram', 'perot', 'dian']\n",
      "['THE PRESIDENTIAL CABINET', 'I APPOINTED THAT SUPREME COURT JUSTICE', 'CABINET DEPARTMENT BY COPS', \"GOV'T & POLITICS\", 'WHAT CABINET DEPARTMENT?', 'STOCKING THE CABINET DEPARTMENT', 'WHICH U.S. CABINET DEPARTMENT?', 'WHICH CABINET DEPARTMENT?', 'THE U.S. TREASURY DEPARTMENT', 'PUT IT IN THE CABINET DEPARTMENT', 'UNDER THIS CABINET DEPARTMENT', 'I SERVED IN HIS CABINET', 'WHO APPOINTED ME TO THE SUPREME COURT?', 'THE FEDERAL GOVERNMENT', 'CABINET DEPARTMENTS', \"IT'S IN THE CABINET DEPARTMENT!\", 'GOVERNMENTAL', 'PRESIDENTIAL SUCCESSION 2010', 'LYNDON JOHNSON', 'LOOK IN THE CABINET', 'LAW HISTORY', 'FORM LETTERS', 'HISTORIC SUPREME COURT DECISIONS', 'I LED WHAT CABINET DEPARTMENT?', 'IN THE CABINET DEPARTMENT']\n",
      "classical music\n",
      "['instrument', 'beethoven', 'grieg', 'bach', 'symphony', 'tycho', 'concerto', 'haydn', 'liszt', 'johann', 'handel', 'cantata', 'bizet', 'ravel', 'percussion', 'philharmonic', 'prokofiev', 'baroque', 'sonata', 'sitar', 'stringed', 'marsalis', 'string', 'classical', 'mozart']\n",
      "[\"YOU'RE NOT ON THE LISZT\", '\\\\\"CL\"ASSICAL MUSIC', '5 \"B\"s OF CLASSICAL MUSIC', \"I DON'T HEAR A SYMPHONY\", 'MUSICAL COMPOSITIONS', 'ORCHESTRAL INSTRUMENTS', 'YOU STAY CLASSICAL, MUSIC', 'MUSIC APPRECIATION', \"THAT'S JUST CLASSIC!\", 'HOW SUITE IT IS', 'EUROPEAN COMPOSERS', 'MAJOR MUSICAL WORKS', 'EARS TO CLASSICAL MUSIC', 'BACH, BEETHOVEN OR BRAHMS', 'THE 3 \"B\"s', 'OUTSIDE THE BACHS', 'ENJOY A CONCERTO', 'CLASSICAL MUSIC AT THE BALLPARK', 'THE JUILLIARD SCHOOL', 'SYMPHON\"E\"s', 'GOING FOR BAROQUE', 'CHAMBER MUSIC', 'CLASSICAL COMPOSERS', 'THIS ONE TIME, AT ORCHESTRA CAMP', 'BALLET MUSIC']\n",
      "fashion\n",
      "['sandal', 'necktie', 'fashion', 'tycho', 'yves', 'scarf', 'stetson', 'handbag', 'skirt', 'worn', 'dior', 'shoe', 'plaid', 'shawl', 'corset', 'dress', 'kilt', 'fez', 'designer', 'bib', 'shirt', 'laurent', 'sneaker', 'garment', 'strap']\n",
      "['FASHION', 'CLOTHING', 'CLOTHES', 'A FASHIONABLE CATEGORY', 'FASHION HISTORY', 'DRESSING', 'FRENCH DRESSING', 'WHAT TO WEAR?', 'DESIGNER INITIALS', 'ALWAYS IN FASHION', 'FASHION ACCESSORIES', 'CLOTHING & FASHION', 'FASHION ABBREV.', \"MEN'S FASHIONS\", 'A STITCH IN TIME', '19th CENTURY FASHION', 'CLOTHING TIME', 'A BIT OLD FASHION', 'FASHION BACKWARD', \"CAN'T HAVE TOO MANY SHOES\", 'OOTD', 'SOMETHING TO WEAR', 'FASHION, HEAD TO FOOT', 'A PASSION FOR FASHION', \"LET'S GET DRESSED IN THE 1920s\"]\n",
      "film\n",
      "['brynner', 'oscar', 'film', 'movie', 'sandler', 'saddles', 'heston', 'hoffman', 'marilyn', 'barbra', 'commandments', 'tarantino', 'hepburn', 'nicholson', 'pacino', 'niro', 'gosling', 'afi', 'meryl', 'tatum', 'frida', 'braveheart', 'darth', 'quaid', 'moonstruck']\n",
      "['OSCAR-WINNING DIRECTORS', 'FIGHTING FOR AN OSCAR', 'THE MOVIES', \"FILMS OF THE '70s\", 'THE OSCARS', \"THE AFI'S 100 GREATEST AMERICAN MOVIES\", \"& THE OSCAR DOESN'T GO TO\", 'THE SILVER SCREEN', 'MOVIE DIRECTORS', '4-LETTER FILMS', 'THE ACADEMY AWARDS', 'OSCAR HISTORY', 'DIRECTING THEIR WIVES', \"THE AFI's 100 YEARS... 100 MOVIES\", 'ACTOR-DIRECTORS', 'A ROLE FOR THE DIRECTOR', \"FILMS OF THE '90s\", 'THEY ALMOST STARRED IN...', 'GENE WILDER', 'WESTERNS', 'MOVIES', \"FILMS OF THE '60s\", 'THE RAZZIES FOR 2009', 'ACTORS & ACTRESSES', 'RECENT MOVIES']\n",
      "food\n",
      "['dish', 'charlton', 'caramel', 'cream', 'flavor', 'wine', 'fruit', 'pasta', 'yul', 'cheese', 'tofu', 'juice', 'tequila', 'sauce', 'fried', 'vodka', 'dessert', 'recipe', 'potable', 'emeril', 'brewed', 'beer', 'baskin', 'isak', 'sandwich']\n",
      "['FOOD & DRINK', 'FOOD', 'FOOD FACTS', 'INTERNATIONAL CUISINE', 'INTERNATIONAL FOOD & DRINK', 'RECIPES', '\\\\\"C\" FOOD', 'JUST DESSERTS', 'THE FANNIE FARMER COOKBOOK', 'NATIONAL FOODS', \"WHAT'S FOR LUNCH?\", 'TEEN CUISINE', 'COOKING', 'RUSSIAN FOOD & DRINK', 'ITALIAN FOOD', 'FOOD STUFF', \"LET'S EAT\", 'JOY OF COOKING', 'WOULD YOU LIKE A COCKTAIL?', 'FOOD TALK', 'ALL-AMERICAN FOOD', 'FRENCH COOKING', 'SOMETHING TO EAT', 'SWEETS', 'COOKING CLASS']\n",
      "geography\n",
      "['picchu', 'stoker', 'angeles', 'penh', 'bhutto', 'capital', 'taj', 'ivy', 'brynner', 'aires', 'university', 'tel', 'lanka', 'selassie', 'minh', 'dinesen', 'flag', 'chaney', 'mile', 'usc', 'urals', 'judi', 'peak', 'azores', 'natchez']\n",
      "['\\\\\"A\" IN GEOGRAPHY', 'THE LARGEST IN AREA', 'GEOGRAPHY', 'IT BORDERS BOTH', 'ON THE MAP', 'STATE BORDERS', 'WORLD GEOGRAPHY', 'U.S. BODIES OF WATER', 'THE LARGEST U.S. STATE', \"STATES' HIGHEST POINTS\", 'ASIAN GEOGRAPHY', 'TOUGH GEOGRAPHY', 'GEOGRAPHY \"B\\\\\"', 'THE MOST POPULOUS NATION', 'PEAKS & VALLEYS', 'THE SMALLEST IN AREA', 'BODIES OF WATER', '\\\\\"F\" IN GEOGRAPHY', 'DID THEY MOVE IT?', 'ALLITERATION ON THE MAP', 'BORDERLINE STATES', 'EUROPEAN GEOGRAPHY', 'DIRECTIONAL GEOGRAPHY', 'LAKES & RIVERS', 'HITHER & YON']\n",
      "history\n",
      "['benazir', 'brahe', 'yul', 'viii', 'minister', 'declaration', 'isak', 'golda', 'luther', 'century', 'guildenstern', 'emperor', '20th', '19th', 'aires', 'throne', 'carta', 'selassie', 'treaty', 'war', 'prime', 'antoinette', 'clouds', 'ii', 'signer']\n",
      "['THE BRITISH MONARCH WHEN...', 'KINGS & QUEENS', 'ROYAL RELATIVES', 'THE ENGLISH MONARCH WHEN...', 'TEENS IN HISTORY', 'OLD HISTORY', 'MILITARY LEADERS', \"ROYAL NAME'S THE SAME\", 'KING TAKES QUEEN', 'EUROPEAN RULERS', 'MONARCHS', 'RULERS', 'U.K. PRIME MINISTERS', \"WHICH BRITISH MONARCH'S REIGN?\", 'ENGLISH KINGS', 'BATTLES', 'ABDICATIONS', 'HEIRS', 'HISTORIC ROYAL RELATIVES', 'CIVIL WAR', 'THE BRITISH MONARCH WHEN HE BECAME PRESIDENT', 'ROYALTY', 'ENGLISH ROYAL HENRYS', 'FORMER WORLD LEADERS', 'UNION ACTIONS']\n",
      "literature\n",
      "['novel', 'bram', 'sherlock', 'galactica', 'rosencrantz', 'agatha', 'bestseller', 'andersen', 'dickens', 'cormac', 'nonfiction', 'brecht', 'mccullers', 'faerie', 'poe', 'poet', 'austen', 'cristo', 'author', 'seuss', 'poem', 'expectations', 'phnom', 'karenina', 'wordsworth']\n",
      "['FICTIONAL CHARACTERS', 'AUTHORS ON AUTHORS', 'LITERARY CHARACTERS', 'LIT-POURRI', 'FILL IN THE BOOK TITLE', 'REQUIRED READING', 'BRITISH LITERARY CHARACTERS', '19th CENTURY LITERATURE', 'LITERARY QUOTES', '19th CENTURY LIT', 'ENGLISH LIT.', \"DICKENS' WORKS\", 'GOOD BOOKS', 'ENGLISH LIT', 'CLASSIC ENGLISH LIT', '20th CENTURY NOVELS', 'LITERARY POTPOURRI', 'KIDDIE LIT', 'A BIT OF LIT', 'BRIT LIT', 'LITERARY HODGEPODGE', 'LITERARY DEDICATIONS', 'CLASSIC NOVELS', 'PUBLISHED POSTHUMOUSLY', 'LITERARY BEFORE & AFTER']\n",
      "miscellaneous\n",
      "['buenos', 'bhutto', 'machu', 'verb', 'adjective', 'jima', 'letter', 'word', 'yul', 'cinco', 'amerigo', 'gwyneth', 'vowel', 'tycho', 'language', 'phrase', 'knute', 'helmut', 'golda', 'hobo', 'natty', 'someone', 'numeral', 'molière', 'slang']\n",
      "['A LANGUAGE OF CONSONANT PLUS VOWEL', '4-LETTER WORDS WITH 1 VOWEL', 'DICTIONARY ABBR.', 'ENDS WITH A SILENT CONSONANT', 'DICTIONARY DEFINITIONS', 'THE DUKE & DUCHESS OF SUFFIX', 'VOCABULARY', 'BAD ENGLISH', 'IN THE DICTIONARY', 'WORD WORDS', 'YOU MAKE ME FEEL', 'THE THINGS YOU SAY!', 'YES', '5 DIFFERENT VOWELS IN ONE WORD', 'GRAMMAR', 'WE\\'LL NEED THE \"RENT\\\\\"', 'SPURN NOTICE', 'SOUNDS JUST LIKE AN ANIMAL', 'FOREIGN WORDS & PHRASES', 'USE YOUR WORD WORDS', 'WORD ODDITIES', 'VOWEL-POURRI', 'ALL THE WAY FROM A TO B', 'WORD ORIGINS', 'A VERY VERSATILE TOOL WORD']\n",
      "pop culture\n",
      "['sci', 'fi', 'ranger', 'las', 'comic', 'angeles', 'monty', 'vegas', 'trek', 'magazine', 'python', 'pooh', 'hulk', 'grecian', 'daredevil', 'sissy', 'willa', 'gon', 'superhero', 'kutcher', 'strip', 'mcentire', 'demi', 'mrs', 'villain']\n",
      "['SCI FI', 'MARVEL COMICS HEROES', 'STAR TREK WRITERS', 'COMIC-CON', 'LEONARD NIMOY FILMS', '\\\\\"OUT\\\\\"', 'TV COMPOSERS', 'SHOW BIZ AWARD WINNERS', 'SCI-FI TV', 'HORROR & SCI-FI TV', 'SCI-FI/FANTASY HEROINES', 'SUPERHEROES', 'MERMAN', 'THE LIBRARIAN INVASIONS', 'SCI-FI SUBGENRES', '...AND MAN CREATED WOMAN', 'ONE-WORD TV CLUES', 'GEEK CONFUSION', 'PUTTING THE \"T\" IN TV', 'SCI FI IDENTIFY', 'THE EISNER AWARDS', 'BOOK & AUTHOR', \"THAT'S ENTERTAINMENT\", 'THE STAN LEE CUP', 'COMIC BOOK CHARACTERS ON SCREEN']\n",
      "pop music\n",
      "['gon', 'band', 'parton', 'halen', 'album', 'billboard', 'song', 'hit', 'aires', 'clapton', 'dogg', 'chart', 'gees', 'redding', 'pistols', 'gaye', 'yul', 'coldplay', 'instrument', 'na', 'aretha', 'charlton', 'stefani', 'cobain', 'ozzy']\n",
      "['POP MUSIC', 'ROCK & ROLL', 'ROCK MUSIC', 'THE BRITISH INVASION', 'ROCK ICONS', 'ROCK OF LOVE', \"\\\\'90s MUSIC\", 'COUNTRY MUSIC', 'ALBUMS', 'SONGS & SINGERS', \"ROCK 'N' ROLL\", 'HEAVY METAL HEROES', 'BRITISH ROCKERS', '\\\\\"ROCK\" IT TO ME', 'NO. 1 HITS', 'WHOSE NO. 1 ALBUM', 'TOP OF THE CHARTS, MA!', 'THE BILLBOARD ALBUM CHARTS', 'ROCK & RAP LETTERS', \"ROCK 'N ROLL\", 'POP & ROCK MUSIC', '21st CENTURY MUSIC', 'LYRICALLY YOURS', \"SONGS OF THE '80s\", \"\\\\'60s ROCK\"]\n",
      "religion\n",
      "['shalt', 'buddhism', 'religion', 'zeus', 'sodom', 'osiris', 'bible', 'goddess', 'isaiah', 'penh', 'noah', 'methuselah', 'perseus', 'genesis', 'revelation', 'ignatius', 'reba', 'hera', 'benazir', 'hinduism', 'ares', 'jesus', 'brynner', 'judges', 'philistines']\n",
      "['BIBLICAL QUOTES', 'BIBLICAL PEOPLE', \"LET'S GET BIBLICAL\", 'THE NEXT BIBLE BOOK AFTER...', 'THE OLD TESTAMENT', 'BIBLICAL PAIRS', 'THE GOOD BOOK', 'THE BIBLE', \"BIBLICAL WHO'S WHO\", 'OMG!', 'THE BIBLE TELLS ME SO', 'BIBLE HEROES', 'THE OLYMPIAN GODS', \"IT'S IN THE BIBLE\", 'BIBLICAL ZOO', 'BIBLICAL PATRIARCHY', 'YAHWEH', 'BOOKS OF THE BIBLE', 'BIBLE BOOKS BY QUOTATION', 'BIBLICAL PEOPLE & PLACES', 'BIBLE BELTS', 'THOU ART DA MAN!', \"WHO'S YOUR MYTHOLOGICAL DADDY?\", 'BIBLE STUDY', 'BIBLE BOOKS BY STORY']\n",
      "science\n",
      "['shuttle', 'com', 'breed', 'brahe', 'element', 'specie', 'akc', 'math', 'disease', 'nobel', 'webbed', 'fossey', 'fertilizer', 'organ', 'mata', 'fetus', 'meir', 'plant', 'mammal', 'insect', 'apollo', 'aldrin', 'computer', 'terrier', 'plasma']\n",
      "['SCIENCE & NATURE', 'BIOLOGY', 'GENERAL SCIENCE', 'THE BODY HUMAN', 'SCIENCE', 'PHYSICAL SCIENCE', 'ANIMALS', 'THE HUMAN BODY', 'ASTRONOMY & SPACE', 'ZOOLOGY', 'SPACE SCIENCE', 'SIMPLE SCIENCE', 'NATURE', 'SCIENCE STUFF', 'HEALTH & MEDICINE', 'ANATOMY', 'SCIENCE CLASS', 'SPACE MISSIONS', \"THAT'S ELEMENT-ARY\", 'SCIENCE NEWS', 'HEALTH MATTERS', 'SICKNESS & HEALTH', 'MAMMALS', 'MEDICINE', 'EPONYMOUS SCIENCE']\n",
      "sports\n",
      "['card', 'sport', 'backgammon', 'haile', 'ball', 'olympic', 'bhutto', 'slalom', 'game', 'team', 'heavyweight', 'blackjack', 'hockey', 'nhl', '49ers', 'steelers', 'badminton', 'medal', 'braves', 'wilma', 'chess', 'baseball', 'slam', 'soccer', 'frazier']\n",
      "['SPORTS LEGENDS', 'SPORTS STARS', 'ATHLETES', 'GOOD SPORTS', 'SPORTS TRIVIA', 'SPORTS GREATS', 'SPORTS NICKNAMES', 'LEGENDS OF SPORTS', 'PLAY BALL!', 'THE SPORTING LIFE', 'SPORTSWOMEN', 'WE ARE THE CHAMPIONS', 'SPORTS-POURRI', 'OLYMPIC GOLD MEDALISTS', 'SPORTS NUMBERS', 'SPORTS CITIES', 'COACH', '21st CENTURY SPORTS', 'BASEBALL ROOKIES OF THE YEAR', \"IT'S A GAMBLE\", 'SPORTS IN THE NEWS', 'SPORTS TALK', 'CHAMPIONS OF TOURNAMENTS', 'SPORTS', 'PROFESSIONAL SPORTS']\n",
      "television\n",
      "['sitcom', 'tv', 'emmy', 'episode', 'mcbeal', 'dench', 'beverly', 'cbs', 'show', 'cw', 'network', 'paltrow', 'mork', 'dyke', 'squarepants', 'host', 'buffy', 'nbc', 'abc', 'ties', 'heroes', 'sopranos', 'erica', 'chaney', 'spongebob']\n",
      "['TV ON TV', 'TV SPIN-OFFS', 'CLASSIC TV SITCOMS', \"TOTALLY AWESOME '80s TV\", 'CLASSIC SITCOM EPISODES', 'TV CHARACTERS', 'TV', 'TV DANS', '\\\\\"THE\" TV SHOW', 'SITCOMS', 'FAMILY TELEVISION', 'CLASSIC TV', 'TV CROSSOVERS', 'THE EMMYS', 'THE 1970 TV SEASON', \"EMMY'S BEST DRAMA\", 'CLASSIC SITCOMS BY EPISODE TITLE', 'TV PERSONALITIES', '1999 TELEVISION', 'THE TV SHOW IN QUESTION', \"2016 PEOPLE'S CHOICE TV WINNERS\", '1999 TELEVISION PREMIERES', 'TV THEME SONGS', 'LAST EPISODES', \"\\\\'80s TV\"]\n",
      "theater\n",
      "['broadway', 'shakespeare', 'bram', 'puccini', 'rosencrantz', 'rossini', 'opera', 'traviata', 'ballet', 'pagliacci', 'macbeth', 'prospero', 'andronicus', 'falstaff', 'hamlet', 'dance', 'midsummer', 'firebird', 'ado', 'revival', 'musical', 'sondheim', 'twelfth', 'ibsen', 'othello']\n",
      "['SHAKESPEAREAN OPERAS', \"SHAKESPEARE'S WOMEN\", \"SHAKESPEARE'S OPENING LINES\", \"SHAKESPEARE'S SETTINGS\", 'SHAKESPEAREAN LAST SCENES', 'SHAKESPEAREAN CHARACTERS', 'SHAKESPEARE ON BROADWAY', 'RARELY QUOTED SHAKESPEARE LINES', 'SHAKESPEARE PLAYS BY CHARACTER', 'ITALIAN OPERA', \"SHAKESPEARE'S COMEDIES\", 'SHAKESPEAREAN TRIVIA', 'THE WEDDED OPERA CATEGORY', 'SHAKESPEAREAN GEOGRAPHY', 'MUSICAL THEATER', 'LOVE IN SHAKESPEARE', 'SHAKESPEAREAN OPERAS & BALLETS', 'SCRAMBLED OPERAS', \"SHAKESPEARE'S TRAGIC CAST\", 'SHAKESPEARE PLAY BY GRADUALLY EASIER CHARACTER', 'SHAKESPEARE SETS THE PLAY', 'WORDS SHAKESPEARE ONLY USED ONCE', 'SHAKING UP SHAKESPEARE', 'CLUE: THE SHAKESPEARE VERSION', 'OPENING LINES OF SHAKESPEARE']\n"
     ]
    }
   ],
   "source": [
    "just_cats = for_cats_std_with_tags[['category']]\n",
    "\n",
    "for tag in tags:\n",
    "    df_spare = for_cats_std_with_tags[[tag, 'all_term_list2']]\n",
    "    df_spare\n",
    "    \n",
    "    target_array_full = np.asarray(df_spare[tag])\n",
    "    corpus = [str(item).lower() for item in df_spare['all_term_list2']]\n",
    "    \n",
    "    tfid_max = int(len(df_spare['all_term_list2'])*.9)\n",
    "    tfid_vectorizer_all = TfidfVectorizer(ngram_range=(1,1), min_df=32, max_df=tfid_max, stop_words=stopwords_list)\n",
    "    full_corpus_vectorizer = tfid_vectorizer_all.fit(corpus)\n",
    "    feature_matrix = tfid_vectorizer_all.transform(corpus)\n",
    "    \n",
    "    #print(feature_matrix.shape)\n",
    "    #print(target_array_full.shape)\n",
    "\n",
    "    lreg = LinearRegression()\n",
    "    lreg.fit(feature_matrix, target_array_full)\n",
    "    coefficients = list(lreg.coef_)\n",
    "    \n",
    "    feature_names = tfid_vectorizer_all.get_feature_names_out()\n",
    "    df = pd.DataFrame(list(zip(feature_names, coefficients)), \n",
    "                   columns =['Feature', 'Coefficient']) \n",
    "    \n",
    "    df_nonzero = df[df['Coefficient'] != 0].sort_values('Coefficient', ascending=False) #only shows non-zero coefficients\n",
    "\n",
    "    # print the name of the category, highest-coeffieicent features for each category, and the categories most confidently labeled by the model\n",
    "    \n",
    "    print(tag)\n",
    "    print(list(df_nonzero['Feature'][:25]))\n",
    "\n",
    "    fieldname = tag + '_predict'\n",
    "    just_cats[fieldname] = lreg.predict(feature_matrix)\n",
    "    \n",
    "    print(list(just_cats.sort_values(fieldname, ascending=False)['category'].head(25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3364b98-88cb-4fdc-bd98-e3d7a4c67816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>art_predict</th>\n",
       "      <th>business_predict</th>\n",
       "      <th>civics_predict</th>\n",
       "      <th>classical music_predict</th>\n",
       "      <th>fashion_predict</th>\n",
       "      <th>film_predict</th>\n",
       "      <th>food_predict</th>\n",
       "      <th>geography_predict</th>\n",
       "      <th>history_predict</th>\n",
       "      <th>...</th>\n",
       "      <th>miscellaneous_predict</th>\n",
       "      <th>pop culture_predict</th>\n",
       "      <th>pop music_predict</th>\n",
       "      <th>religion_predict</th>\n",
       "      <th>science_predict</th>\n",
       "      <th>sports_predict</th>\n",
       "      <th>television_predict</th>\n",
       "      <th>theater_predict</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POTPOURRI</td>\n",
       "      <td>-0.029759</td>\n",
       "      <td>0.096773</td>\n",
       "      <td>-0.025515</td>\n",
       "      <td>0.075611</td>\n",
       "      <td>0.080765</td>\n",
       "      <td>-0.109308</td>\n",
       "      <td>0.092537</td>\n",
       "      <td>-0.034043</td>\n",
       "      <td>-0.025516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897951</td>\n",
       "      <td>0.044325</td>\n",
       "      <td>-0.090573</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.178650</td>\n",
       "      <td>-0.017369</td>\n",
       "      <td>-0.035231</td>\n",
       "      <td>-0.034387</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>-0.046719</td>\n",
       "      <td>-0.052214</td>\n",
       "      <td>-0.037531</td>\n",
       "      <td>-0.013426</td>\n",
       "      <td>-0.040556</td>\n",
       "      <td>-0.102427</td>\n",
       "      <td>-0.075252</td>\n",
       "      <td>-0.128446</td>\n",
       "      <td>-0.237420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>-0.042338</td>\n",
       "      <td>-0.099393</td>\n",
       "      <td>-0.078480</td>\n",
       "      <td>1.682990</td>\n",
       "      <td>-0.030361</td>\n",
       "      <td>-0.063732</td>\n",
       "      <td>-0.028780</td>\n",
       "      <td>science</td>\n",
       "      <td>miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>-0.024625</td>\n",
       "      <td>-0.021783</td>\n",
       "      <td>-0.042847</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>-0.061100</td>\n",
       "      <td>-0.008865</td>\n",
       "      <td>-0.026848</td>\n",
       "      <td>-0.151515</td>\n",
       "      <td>-0.151557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623776</td>\n",
       "      <td>-0.022784</td>\n",
       "      <td>-0.098462</td>\n",
       "      <td>-0.049602</td>\n",
       "      <td>-0.170063</td>\n",
       "      <td>0.061940</td>\n",
       "      <td>-0.054588</td>\n",
       "      <td>0.073249</td>\n",
       "      <td>literature</td>\n",
       "      <td>miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>-0.060064</td>\n",
       "      <td>-0.016574</td>\n",
       "      <td>-0.017587</td>\n",
       "      <td>-0.016052</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>-0.024449</td>\n",
       "      <td>0.093253</td>\n",
       "      <td>0.837478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844460</td>\n",
       "      <td>-0.081791</td>\n",
       "      <td>-0.087518</td>\n",
       "      <td>-0.058953</td>\n",
       "      <td>-0.135501</td>\n",
       "      <td>-0.092426</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>-0.008531</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMERICAN HISTORY</td>\n",
       "      <td>-0.056226</td>\n",
       "      <td>0.014678</td>\n",
       "      <td>0.039657</td>\n",
       "      <td>-0.004201</td>\n",
       "      <td>-0.030702</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>-0.029202</td>\n",
       "      <td>-0.048329</td>\n",
       "      <td>0.631631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903155</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>-0.009155</td>\n",
       "      <td>-0.091708</td>\n",
       "      <td>-0.086370</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>-0.047031</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  art_predict  business_predict  civics_predict  \\\n",
       "0         POTPOURRI    -0.029759          0.096773       -0.025515   \n",
       "1           SCIENCE    -0.046719         -0.052214       -0.037531   \n",
       "2        LITERATURE    -0.024625         -0.021783       -0.042847   \n",
       "3           HISTORY    -0.060064         -0.016574       -0.017587   \n",
       "4  AMERICAN HISTORY    -0.056226          0.014678        0.039657   \n",
       "\n",
       "   classical music_predict  fashion_predict  film_predict  food_predict  \\\n",
       "0                 0.075611         0.080765     -0.109308      0.092537   \n",
       "1                -0.013426        -0.040556     -0.102427     -0.075252   \n",
       "2                 0.008082        -0.061100     -0.008865     -0.026848   \n",
       "3                -0.016052         0.003580      0.000356     -0.024449   \n",
       "4                -0.004201        -0.030702      0.005750     -0.029202   \n",
       "\n",
       "   geography_predict  history_predict  ...  miscellaneous_predict  \\\n",
       "0          -0.034043        -0.025516  ...               0.897951   \n",
       "1          -0.128446        -0.237420  ...               0.505226   \n",
       "2          -0.151515        -0.151557  ...               0.623776   \n",
       "3           0.093253         0.837478  ...               0.844460   \n",
       "4          -0.048329         0.631631  ...               0.903155   \n",
       "\n",
       "   pop culture_predict  pop music_predict  religion_predict  science_predict  \\\n",
       "0             0.044325          -0.090573          0.021820         0.178650   \n",
       "1            -0.042338          -0.099393         -0.078480         1.682990   \n",
       "2            -0.022784          -0.098462         -0.049602        -0.170063   \n",
       "3            -0.081791          -0.087518         -0.058953        -0.135501   \n",
       "4            -0.018148           0.013504         -0.009155        -0.091708   \n",
       "\n",
       "   sports_predict  television_predict  theater_predict    max_predict  \\\n",
       "0       -0.017369           -0.035231        -0.034387  miscellaneous   \n",
       "1       -0.030361           -0.063732        -0.028780        science   \n",
       "2        0.061940           -0.054588         0.073249     literature   \n",
       "3       -0.092426           -0.012939        -0.008531  miscellaneous   \n",
       "4       -0.086370            0.006012        -0.047031  miscellaneous   \n",
       "\n",
       "  second_max_predict  \n",
       "0            science  \n",
       "1      miscellaneous  \n",
       "2      miscellaneous  \n",
       "3            history  \n",
       "4            history  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the predicted values in one frame and maximum predicted value\n",
    "\n",
    "just_cats['max_predict'] = just_cats.iloc[:,1:19].idxmax(axis=1).str.replace('_predict','')\n",
    "just_cats['second_max_predict'] = just_cats.iloc[:, 1:19].apply(lambda row: row.nlargest(2).idxmin(), axis=1).str.replace('_predict','')\n",
    "\n",
    "#just_cats.to_csv('just_cats_linear_reg_08022025.csv') #to save the output\n",
    "just_cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b3602-ae2e-4fd8-9c18-e1476ce29776",
   "metadata": {},
   "source": [
    "I also made the following manual edits on the output file:\n",
    "\n",
    "1. Remove all secondary tags of \"miscellaneous\"\n",
    "2. Remove all secondary tags where the gap between the highest and second-highest predicted value is greater than 0.5\n",
    "3. Replaced \"miscellaneous\" primary tags  with the secondary predicted tag on categories with especially high secondary predicted values\n",
    "4. Reviewed remaining \"miscellaneous\" categories in the top 500 and edited where needed\n",
    "5. Removed all remaining secondary tags <0.19 predicted score\n",
    "6. Removed all remaining secondary tags <0.3 predicted score and gap greater than 0.1\n",
    "7. Miscellaneous additional ad hoc edits\n",
    "\n",
    "If you do this yourself, don't worry too much about the accuracy of categories below the first couple thousand; nearly every category name is only used once, so a stray \"Puccini\" in an otherwise miscellaneous category could get it flagged as opera. The top 10,000 categories (of 55,000) comprise approximately 60% of the total clue corpus. As well, short of a systematic review nothing I have done to modify the labels has significantly impacted the takeaways from the below applications (get rate order doesn't change significantly, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f514a-3c3a-43c1-bcc0-b834a89aad49",
   "metadata": {},
   "source": [
    "# Applications of Labeled Category Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac0638-d1c3-4e2b-9cfc-16a14c43fa65",
   "metadata": {},
   "source": [
    "### Category Get Rates\n",
    "\n",
    "Once again: I am aware my code sucks.\n",
    "\n",
    "This is code that imports \"processed games 9 4\" - a dataset including details about game flow and correct answers - and marks clues for whether _at least one contestant_ answered the question correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "567cdd5d-fd57-47dd-bf95-1c53ea86fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tags = pd.read_csv('cats_with_tags_final_2025.csv')\n",
    "game_flow_data = pd.read_csv('processed_games_9_4.csv')\n",
    "\n",
    "j = pd.read_pickle('s41_cleaned.pkl')\n",
    "questions_with_cats = pd.merge(j, category_tags, on='category')\n",
    "questions_with_cats['year'] = [int(i[:4]) for i in questions_with_cats.air_date]\n",
    "questions_with_cats['daily_double'] = [i > 0 for i in questions_with_cats.daily_double_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbd0a97f-d9dc-4484-8c3f-cde0a69d83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_trunc = questions_with_cats[['air_date', 'round', 'category', 'answer', 'question', 'clue_value', 'max_predict', 'second_max_predict']]\n",
    "gameflow_trunc = game_flow_data[['airdate', 'clue_text', 'clue_values', 'clue_answers', 'player1_right', 'player2_right',\n",
    "       'player3_right', 'player1_wrong', 'player2_wrong', 'player3_wrong', 'dd_flag']]\n",
    "\n",
    "getrate = questions_trunc.merge(gameflow_trunc, left_on=['air_date', 'question'], right_on=['airdate', 'clue_answers'], how='inner')\n",
    "\n",
    "getrate['correct'] = getrate['player1_right'] + getrate['player2_right'] + getrate['player3_right']\n",
    "getrate['wrong'] = getrate['player1_wrong'] + getrate['player2_wrong'] + getrate['player3_wrong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ed082cb-6932-4c88-a3e7-4b007931dbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "      <th>airdate</th>\n",
       "      <th>clue_text</th>\n",
       "      <th>...</th>\n",
       "      <th>player2_wrong</th>\n",
       "      <th>player3_wrong</th>\n",
       "      <th>dd_flag</th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>two_tags</th>\n",
       "      <th>correct_weight</th>\n",
       "      <th>correct_value</th>\n",
       "      <th>claimed_dollars</th>\n",
       "      <th>claimable_dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101789</th>\n",
       "      <td>2012-01-10</td>\n",
       "      <td>2</td>\n",
       "      <td>COMICS STRIP</td>\n",
       "      <td>Ken Jeong bared all as crime lord Mr. Chow in ...</td>\n",
       "      <td>The Hangover</td>\n",
       "      <td>2000</td>\n",
       "      <td>pop culture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-10</td>\n",
       "      <td>Ken Jeong bared all as crime lord Mr. Chow in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173684</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>1</td>\n",
       "      <td>NOT FOR PROFIT</td>\n",
       "      <td>The NRDC fights for clean energy &amp; against pow...</td>\n",
       "      <td>coal</td>\n",
       "      <td>200</td>\n",
       "      <td>science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>The NRDC fights for clean energy &amp; against pow...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148597</th>\n",
       "      <td>2016-07-22</td>\n",
       "      <td>1</td>\n",
       "      <td>THE BUCKET LIST</td>\n",
       "      <td>Bucket seats in cars were popularized by this ...</td>\n",
       "      <td>Chevy</td>\n",
       "      <td>800</td>\n",
       "      <td>film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-22</td>\n",
       "      <td>Bucket seats in cars were popularized by this ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222462</th>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>1</td>\n",
       "      <td>WORLD OF FOOD</td>\n",
       "      <td>This name for a pizza turnover comes from the ...</td>\n",
       "      <td>calzone</td>\n",
       "      <td>200</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>This name for a pizza turnover comes from the ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>2002-04-24</td>\n",
       "      <td>1</td>\n",
       "      <td>LARRY, MOE OR CURLY</td>\n",
       "      <td>Leisure-suited lounge lizard who's starred in ...</td>\n",
       "      <td>Larry</td>\n",
       "      <td>800</td>\n",
       "      <td>television</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-04-24</td>\n",
       "      <td>Leisure-suited lounge lizard who's starred in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          air_date  round             category  \\\n",
       "101789  2012-01-10      2         COMICS STRIP   \n",
       "173684  2018-12-24      1       NOT FOR PROFIT   \n",
       "148597  2016-07-22      1      THE BUCKET LIST   \n",
       "222462  2023-07-05      1        WORLD OF FOOD   \n",
       "3768    2002-04-24      1  LARRY, MOE OR CURLY   \n",
       "\n",
       "                                                   answer      question  \\\n",
       "101789  Ken Jeong bared all as crime lord Mr. Chow in ...  The Hangover   \n",
       "173684  The NRDC fights for clean energy & against pow...          coal   \n",
       "148597  Bucket seats in cars were popularized by this ...         Chevy   \n",
       "222462  This name for a pizza turnover comes from the ...       calzone   \n",
       "3768    Leisure-suited lounge lizard who's starred in ...         Larry   \n",
       "\n",
       "        clue_value  max_predict second_max_predict     airdate  \\\n",
       "101789        2000  pop culture                NaN  2012-01-10   \n",
       "173684         200      science                NaN  2018-12-24   \n",
       "148597         800         film                NaN  2016-07-22   \n",
       "222462         200         food                NaN  2023-07-05   \n",
       "3768           800   television                NaN  2002-04-24   \n",
       "\n",
       "                                                clue_text  ...  player2_wrong  \\\n",
       "101789  Ken Jeong bared all as crime lord Mr. Chow in ...  ...            0.0   \n",
       "173684  The NRDC fights for clean energy & against pow...  ...            0.0   \n",
       "148597  Bucket seats in cars were popularized by this ...  ...            0.0   \n",
       "222462  This name for a pizza turnover comes from the ...  ...            0.0   \n",
       "3768    Leisure-suited lounge lizard who's starred in ...  ...            0.0   \n",
       "\n",
       "       player3_wrong  dd_flag  correct  wrong  two_tags  correct_weight  \\\n",
       "101789           0.0        0      1.0    0.0     False             1.0   \n",
       "173684           0.0        0      1.0    0.0     False             1.0   \n",
       "148597           0.0        0      1.0    0.0     False             1.0   \n",
       "222462           0.0        0      1.0    0.0     False             1.0   \n",
       "3768             0.0        0      1.0    0.0     False             1.0   \n",
       "\n",
       "        correct_value  claimed_dollars  claimable_dollars  \n",
       "101789            1.0           2000.0             2000.0  \n",
       "173684            1.0            200.0              200.0  \n",
       "148597            1.0            800.0              800.0  \n",
       "222462            1.0            200.0              200.0  \n",
       "3768              1.0            800.0              800.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getrate['two_tags'] = getrate.second_max_predict.notnull()\n",
    "getrate['correct_weight'] = [0.5 if i == True else 1.0 for i in getrate.two_tags] \n",
    "getrate['correct_value'] = getrate.correct * getrate.correct_weight\n",
    "getrate['claimed_dollars'] = getrate.correct_value * getrate.clue_value \n",
    "getrate['claimable_dollars'] = getrate.correct_weight * getrate.clue_value \n",
    "getrate.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82f9a87d-8eed-4fdb-9c6c-da78120d1822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>category</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134276</th>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>COMPOUND WORDS</td>\n",
       "      <td>A ship's cockpit is this enclosed area on the ...</td>\n",
       "      <td>wheelhouse</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33950</th>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>FRED THOMPSON, ACTING SENATOR</td>\n",
       "      <td>Fred Dalton Thompson was still in the Senate w...</td>\n",
       "      <td>Law &amp; Order</td>\n",
       "      <td>civics</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111310</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>PEOPLE ARE READING...</td>\n",
       "      <td>\\\"An American Son\", by this senator whose pare...</td>\n",
       "      <td>Marco Rubio</td>\n",
       "      <td>literature</td>\n",
       "      <td>pop music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104110</th>\n",
       "      <td>2012-04-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>KISSING</td>\n",
       "      <td>Ryabovich gets a kiss by mistake from a myster...</td>\n",
       "      <td>Chekhov</td>\n",
       "      <td>literature</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45964</th>\n",
       "      <td>2006-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>A LITERARY TOUR</td>\n",
       "      <td>Have a homey lunch at this author's Salinas, C...</td>\n",
       "      <td>John Steinbeck</td>\n",
       "      <td>literature</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          air_date  round  clue_value                       category  \\\n",
       "134276  2015-04-15      2        2000                 COMPOUND WORDS   \n",
       "33950   2005-09-12      1         200  FRED THOMPSON, ACTING SENATOR   \n",
       "111310  2012-12-31      1         200          PEOPLE ARE READING...   \n",
       "104110  2012-04-04      1        1000                        KISSING   \n",
       "45964   2006-10-12      1         600                A LITERARY TOUR   \n",
       "\n",
       "                                                   answer        question  \\\n",
       "134276  A ship's cockpit is this enclosed area on the ...      wheelhouse   \n",
       "33950   Fred Dalton Thompson was still in the Senate w...     Law & Order   \n",
       "111310  \\\"An American Son\", by this senator whose pare...     Marco Rubio   \n",
       "104110  Ryabovich gets a kiss by mistake from a myster...         Chekhov   \n",
       "45964   Have a homey lunch at this author's Salinas, C...  John Steinbeck   \n",
       "\n",
       "          max_predict second_max_predict  \n",
       "134276  miscellaneous                NaN  \n",
       "33950          civics               film  \n",
       "111310     literature          pop music  \n",
       "104110     literature                NaN  \n",
       "45964      literature                NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getrate[['air_date','round','clue_value','category','answer','question','max_predict', 'second_max_predict']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce2caf-59b8-45c4-bc30-b1bcd77bbf43",
   "metadata": {},
   "source": [
    "This data only covers games since 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "775bc485-9934-4c91-a1ef-a241136d72bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2002-01-01'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(getrate['air_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0b59b70-7268-4dd2-8022-91f4b350a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-07-25'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(getrate['air_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a1337ba-f0a2-4a68-a66d-dd4c882cfa59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>value</th>\n",
       "      <th>getrate</th>\n",
       "      <th>correct</th>\n",
       "      <th>clues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>overall</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.959177</td>\n",
       "      <td>21322.5</td>\n",
       "      <td>22230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overall</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>0.918826</td>\n",
       "      <td>20278.5</td>\n",
       "      <td>22070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overall</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>0.881075</td>\n",
       "      <td>19407.0</td>\n",
       "      <td>22026.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>overall</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>0.840175</td>\n",
       "      <td>18462.0</td>\n",
       "      <td>21974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>overall</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>16299.5</td>\n",
       "      <td>21704.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>overall</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0.936496</td>\n",
       "      <td>20395.0</td>\n",
       "      <td>21778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overall</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.877490</td>\n",
       "      <td>19070.5</td>\n",
       "      <td>21733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>overall</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.813987</td>\n",
       "      <td>17650.5</td>\n",
       "      <td>21684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>overall</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.745358</td>\n",
       "      <td>16118.0</td>\n",
       "      <td>21624.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>overall</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.645195</td>\n",
       "      <td>13672.0</td>\n",
       "      <td>21190.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category  round  value   getrate  correct    clues\n",
       "0  overall      1    200  0.959177  21322.5  22230.0\n",
       "1  overall      1    400  0.918826  20278.5  22070.0\n",
       "2  overall      1    600  0.881075  19407.0  22026.5\n",
       "3  overall      1    800  0.840175  18462.0  21974.0\n",
       "4  overall      1   1000  0.750973  16299.5  21704.5\n",
       "5  overall      2    400  0.936496  20395.0  21778.0\n",
       "6  overall      2    800  0.877490  19070.5  21733.0\n",
       "7  overall      2   1200  0.813987  17650.5  21684.0\n",
       "8  overall      2   1600  0.745358  16118.0  21624.5\n",
       "9  overall      2   2000  0.645195  13672.0  21190.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rates_cat = pd.DataFrame(columns=['category', 'round', 'value', 'getrate', 'correct', 'clues'])\n",
    "\n",
    "for roundd in [1,2]:\n",
    "    if roundd == 1:\n",
    "        for clue_value in [200,400,600,800,1000]:\n",
    "            subframe = getrate[(getrate['round'] == 1) & (getrate.clue_value == clue_value)]\n",
    "            numer = subframe.correct_value.sum()\n",
    "            denom = subframe.correct_weight.sum()\n",
    "\n",
    "            correct_pct = numer / denom\n",
    "\n",
    "            row = {'category': 'overall', 'round': roundd, 'value': clue_value, 'getrate': correct_pct, 'correct': numer, 'clues': denom}\n",
    "            get_rates_cat.loc[len(get_rates_cat)] = row\n",
    "            \n",
    "    if roundd == 2:\n",
    "        for clue_value in [400,800,1200,1600,2000]:\n",
    "            subframe = getrate[(getrate['round'] == 2) & (getrate.clue_value == clue_value)]\n",
    "            numer = subframe.correct_value.sum()\n",
    "            denom = subframe.correct_weight.sum()\n",
    "\n",
    "            correct_pct = numer / denom\n",
    "\n",
    "            row = {'category': 'overall', 'round': roundd, 'value': clue_value, 'getrate': correct_pct, 'correct': numer, 'clues': denom}\n",
    "            get_rates_cat.loc[len(get_rates_cat)] = row\n",
    "                \n",
    "    #print(str(tag) + ': ' + str(tag_frame.clue_value.mean()))\n",
    "\n",
    "get_rates_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d32090-cdf9-4c31-9258-65f7eef4df58",
   "metadata": {},
   "source": [
    "Generating the by-dollar value and label crosstab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40bef855-1be3-4557-8b12-6dd714783d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>value</th>\n",
       "      <th>getrate</th>\n",
       "      <th>correct</th>\n",
       "      <th>clues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.964623</td>\n",
       "      <td>204.5</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>193.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>art</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>170.5</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>art</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>0.781863</td>\n",
       "      <td>159.5</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>art</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>134.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>theater</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0.928773</td>\n",
       "      <td>658.5</td>\n",
       "      <td>709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>theater</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.858965</td>\n",
       "      <td>606.0</td>\n",
       "      <td>705.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>theater</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.797450</td>\n",
       "      <td>563.0</td>\n",
       "      <td>706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>theater</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.722384</td>\n",
       "      <td>497.0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>theater</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.562829</td>\n",
       "      <td>374.0</td>\n",
       "      <td>664.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    category  round  value   getrate  correct  clues\n",
       "0        art      1    200  0.964623    204.5  212.0\n",
       "1        art      1    400  0.919048    193.0  210.0\n",
       "2        art      1    600  0.852500    170.5  200.0\n",
       "3        art      1    800  0.781863    159.5  204.0\n",
       "4        art      1   1000  0.650485    134.0  206.0\n",
       "..       ...    ...    ...       ...      ...    ...\n",
       "175  theater      2    400  0.928773    658.5  709.0\n",
       "176  theater      2    800  0.858965    606.0  705.5\n",
       "177  theater      2   1200  0.797450    563.0  706.0\n",
       "178  theater      2   1600  0.722384    497.0  688.0\n",
       "179  theater      2   2000  0.562829    374.0  664.5\n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rates_cat = pd.DataFrame(columns=['category', 'round', 'value', 'getrate', 'correct', 'clues'])\n",
    "\n",
    "for tag in tags:\n",
    "    tag_frame = getrate[(getrate.max_predict == tag) | (getrate.second_max_predict == tag)]\n",
    "    #tag_frame = tag_frame[tag_frame.air_date > '2020-01-01']\n",
    "\n",
    "    for roundd in [1,2]:\n",
    "        if roundd == 1:\n",
    "            for clue_value in [200,400,600,800,1000]:\n",
    "                subframe = tag_frame[(tag_frame['round'] == 1) & (tag_frame.clue_value == clue_value)]\n",
    "                numer = subframe.correct_value.sum()\n",
    "                denom = subframe.correct_weight.sum()\n",
    "    \n",
    "                correct_pct = numer / denom\n",
    "\n",
    "                row = {'category': tag, 'round': roundd, 'value': clue_value, 'getrate': correct_pct, 'correct': numer, 'clues': denom}\n",
    "                get_rates_cat.loc[len(get_rates_cat)] = row\n",
    "                \n",
    "        if roundd == 2:\n",
    "            for clue_value in [400,800,1200,1600,2000]:\n",
    "                subframe = tag_frame[(tag_frame['round'] == 2) & (tag_frame.clue_value == clue_value)]\n",
    "                numer = subframe.correct_value.sum()\n",
    "                denom = subframe.correct_weight.sum()\n",
    "    \n",
    "                correct_pct = numer / denom\n",
    "    \n",
    "                row = {'category': tag, 'round': roundd, 'value': clue_value, 'getrate': correct_pct, 'correct': numer, 'clues': denom}\n",
    "                get_rates_cat.loc[len(get_rates_cat)] = row\n",
    "                \n",
    "    #print(str(tag) + ': ' + str(tag_frame.clue_value.mean()))\n",
    "\n",
    "get_rates_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96bb191f-160b-4173-9a5c-770107c7cfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "      <th>airdate</th>\n",
       "      <th>clue_text</th>\n",
       "      <th>...</th>\n",
       "      <th>player2_wrong</th>\n",
       "      <th>player3_wrong</th>\n",
       "      <th>dd_flag</th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>two_tags</th>\n",
       "      <th>correct_weight</th>\n",
       "      <th>correct_value</th>\n",
       "      <th>claimed_dollars</th>\n",
       "      <th>claimable_dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AMERICAN MUSEUMS</td>\n",
       "      <td>The history of evangelism is on display at a W...</td>\n",
       "      <td>Billy Graham</td>\n",
       "      <td>200</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>The history of evangelism is on display at a W...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AMERICAN MUSEUMS</td>\n",
       "      <td>A visit to this soft drink's Waco, Texas museu...</td>\n",
       "      <td>Dr Pepper</td>\n",
       "      <td>400</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>A visit to this soft drink's Waco, Texas museu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AMERICAN MUSEUMS</td>\n",
       "      <td>The last Major Leaguer to hit .400, his Museum...</td>\n",
       "      <td>Ted Williams</td>\n",
       "      <td>600</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>The last Major Leaguer to hit .400, his Museum...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AMERICAN MUSEUMS</td>\n",
       "      <td>Exhibits at Seattle's Museum of Flight are hou...</td>\n",
       "      <td>Boeing</td>\n",
       "      <td>800</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>Exhibits at Seattle's Museum of Flight are hou...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AMERICAN MUSEUMS</td>\n",
       "      <td>Built from 2 slave cabins, the Uncle Remus Mus...</td>\n",
       "      <td>Joel Chandler Harris</td>\n",
       "      <td>1000</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>Built from 2 slave cabins, the Uncle Remus Mus...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     air_date  round          category  \\\n",
       "0  2002-01-01      1  AMERICAN MUSEUMS   \n",
       "1  2002-01-01      1  AMERICAN MUSEUMS   \n",
       "2  2002-01-01      1  AMERICAN MUSEUMS   \n",
       "3  2002-01-01      1  AMERICAN MUSEUMS   \n",
       "4  2002-01-01      1  AMERICAN MUSEUMS   \n",
       "\n",
       "                                              answer              question  \\\n",
       "0  The history of evangelism is on display at a W...          Billy Graham   \n",
       "1  A visit to this soft drink's Waco, Texas museu...             Dr Pepper   \n",
       "2  The last Major Leaguer to hit .400, his Museum...          Ted Williams   \n",
       "3  Exhibits at Seattle's Museum of Flight are hou...                Boeing   \n",
       "4  Built from 2 slave cabins, the Uncle Remus Mus...  Joel Chandler Harris   \n",
       "\n",
       "   clue_value max_predict second_max_predict     airdate  \\\n",
       "0         200   geography                NaN  2002-01-01   \n",
       "1         400   geography                NaN  2002-01-01   \n",
       "2         600   geography                NaN  2002-01-01   \n",
       "3         800   geography                NaN  2002-01-01   \n",
       "4        1000   geography                NaN  2002-01-01   \n",
       "\n",
       "                                           clue_text  ...  player2_wrong  \\\n",
       "0  The history of evangelism is on display at a W...  ...            0.0   \n",
       "1  A visit to this soft drink's Waco, Texas museu...  ...            0.0   \n",
       "2  The last Major Leaguer to hit .400, his Museum...  ...            0.0   \n",
       "3  Exhibits at Seattle's Museum of Flight are hou...  ...            0.0   \n",
       "4  Built from 2 slave cabins, the Uncle Remus Mus...  ...            0.0   \n",
       "\n",
       "  player3_wrong  dd_flag  correct  wrong  two_tags  correct_weight  \\\n",
       "0           0.0        0      1.0    0.0     False             1.0   \n",
       "1           0.0        0      1.0    0.0     False             1.0   \n",
       "2           0.0        0      1.0    0.0     False             1.0   \n",
       "3           0.0        0      1.0    0.0     False             1.0   \n",
       "4           0.0        0      0.0    0.0     False             1.0   \n",
       "\n",
       "   correct_value  claimed_dollars  claimable_dollars  \n",
       "0            1.0            200.0              200.0  \n",
       "1            1.0            400.0              400.0  \n",
       "2            1.0            600.0              600.0  \n",
       "3            1.0            800.0              800.0  \n",
       "4            0.0              0.0             1000.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getrate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91dc3b53-a41c-4c0a-834b-e655be110905",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select max_predict as 'tag', count(*) as clue_count, avg(clue_value) as value\n",
    "from getrate\n",
    "where air_date >= '2011-01-01'\n",
    "group by max_predict\n",
    "UNION ALL\n",
    "select second_max_predict as 'tag', count(*) as clue_count, avg(clue_value) as value\n",
    "from getrate\n",
    "where air_date >= '2011-01-01'\n",
    "group by second_max_predict\n",
    "\"\"\"\n",
    "\n",
    "sqldf(query).to_csv('freq_value.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "062cfe4b-a34a-4445-8796-fdd38c6492ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1_overall</th>\n",
       "      <th>r2_overall</th>\n",
       "      <th>game_overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>0.834787</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>0.784469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>0.873002</td>\n",
       "      <td>0.805150</td>\n",
       "      <td>0.849225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civics</th>\n",
       "      <td>0.865390</td>\n",
       "      <td>0.812227</td>\n",
       "      <td>0.840006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classical music</th>\n",
       "      <td>0.867762</td>\n",
       "      <td>0.763201</td>\n",
       "      <td>0.798930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>0.861571</td>\n",
       "      <td>0.770285</td>\n",
       "      <td>0.835351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>0.897778</td>\n",
       "      <td>0.832265</td>\n",
       "      <td>0.860796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.879623</td>\n",
       "      <td>0.835254</td>\n",
       "      <td>0.867306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geography</th>\n",
       "      <td>0.861584</td>\n",
       "      <td>0.794993</td>\n",
       "      <td>0.827925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>0.856423</td>\n",
       "      <td>0.788117</td>\n",
       "      <td>0.819853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>literature</th>\n",
       "      <td>0.843526</td>\n",
       "      <td>0.763640</td>\n",
       "      <td>0.795631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.878483</td>\n",
       "      <td>0.825065</td>\n",
       "      <td>0.854498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop culture</th>\n",
       "      <td>0.884508</td>\n",
       "      <td>0.837936</td>\n",
       "      <td>0.860958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop music</th>\n",
       "      <td>0.875136</td>\n",
       "      <td>0.816247</td>\n",
       "      <td>0.845269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>0.867963</td>\n",
       "      <td>0.806002</td>\n",
       "      <td>0.833166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.869800</td>\n",
       "      <td>0.810791</td>\n",
       "      <td>0.838589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>0.876698</td>\n",
       "      <td>0.825762</td>\n",
       "      <td>0.861127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>television</th>\n",
       "      <td>0.888398</td>\n",
       "      <td>0.840220</td>\n",
       "      <td>0.866965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theater</th>\n",
       "      <td>0.869228</td>\n",
       "      <td>0.776994</td>\n",
       "      <td>0.807046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 r1_overall  r2_overall  game_overall\n",
       "category                                             \n",
       "art                0.834787    0.762655      0.784469\n",
       "business           0.873002    0.805150      0.849225\n",
       "civics             0.865390    0.812227      0.840006\n",
       "classical music    0.867762    0.763201      0.798930\n",
       "fashion            0.861571    0.770285      0.835351\n",
       "film               0.897778    0.832265      0.860796\n",
       "food               0.879623    0.835254      0.867306\n",
       "geography          0.861584    0.794993      0.827925\n",
       "history            0.856423    0.788117      0.819853\n",
       "literature         0.843526    0.763640      0.795631\n",
       "miscellaneous      0.878483    0.825065      0.854498\n",
       "pop culture        0.884508    0.837936      0.860958\n",
       "pop music          0.875136    0.816247      0.845269\n",
       "religion           0.867963    0.806002      0.833166\n",
       "science            0.869800    0.810791      0.838589\n",
       "sports             0.876698    0.825762      0.861127\n",
       "television         0.888398    0.840220      0.866965\n",
       "theater            0.869228    0.776994      0.807046"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select category, round, 'tot.' as value, sum(correct) / sum(clues) as 'getrate', sum(correct) as correct, sum(clues) as clues\n",
    "from get_rates_cat\n",
    "group by category, round\n",
    "UNION ALL\n",
    "select category, 'tot.' as round, 'tot.' as value, sum(correct) / sum(clues) as 'getrate', sum(correct) as correct, sum(clues) as clues\n",
    "from get_rates_cat\n",
    "group by category\n",
    "\"\"\"\n",
    "\n",
    "round_and_game = sqldf(query)\n",
    "\n",
    "overall_pivot = round_and_game.pivot(index='category', columns=['round', 'value'])['getrate']\n",
    "\n",
    "overall_pivot.columns = ['r1_overall', 'r2_overall', 'game_overall']\n",
    "\n",
    "overall_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "97283de2-9be8-4ee5-acd3-319bf99cac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_pivot = get_rates_cat.pivot(index='category', columns=['round', 'value'])['getrate']\n",
    "\n",
    "rate_pivot.columns = ['1-200', '1-400', '1-600', '1-800', '1-1000', '2-400', '2-800', '2-1200', '2-1600', '2-2000']\n",
    "\n",
    "overall_pivot.join(rate_pivot, how='left').sort_values('game_overall', ascending=False).to_csv('getrates_12282025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "2c1bb9fe-7923-48b9-9d59-f4799e3beeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art|0.717|2475000.0|3451200.0\n",
      "business|0.800|4037800.0|5043500.0\n",
      "civics|0.789|2502400.0|3168100.0\n",
      "classical music|0.729|1347000.0|1846300.0\n",
      "fashion|0.778|982500.0|1261400.0\n",
      "film|0.810|9351000.0|11530600.0\n",
      "food|0.823|5297300.0|6430600.0\n",
      "geography|0.772|20574700.0|26644400.0\n",
      "history|0.760|23867800.0|31365500.0\n",
      "literature|0.733|12969600.0|17681800.0\n",
      "miscellaneous|0.807|37114200.0|45950600.0\n",
      "pop culture|0.813|2391100.0|2938500.0\n",
      "pop music|0.792|5980600.0|7550400.0\n",
      "religion|0.777|3619600.0|4657000.0\n",
      "science|0.787|19056800.0|24209700.0\n",
      "sports|0.818|5579900.0|6821300.0\n",
      "television|0.826|5824400.0|7051200.0\n",
      "theater|0.742|3809900.0|5129300.0\n"
     ]
    }
   ],
   "source": [
    "# alternative view not used in article: pct of all claimed dollars\n",
    "\n",
    "for tag in tags:\n",
    "    tag_frame = getrate[(getrate.max_predict == tag) | (getrate.second_max_predict == tag)]\n",
    "    #tag_frame = tag_frame[tag_frame.air_date > '2020-01-01\n",
    "\n",
    "    subframe = tag_frame\n",
    "    numer = subframe.claimed_dollars.sum()\n",
    "    denom = subframe.claimable_dollars.sum()\n",
    "    \n",
    "    correct_pct = numer / denom\n",
    "\n",
    "    print(str(tag) +  '|' + str(correct_pct)[:5] + '|' + str(numer) + '|' + str(denom))\n",
    "    #print(str(tag) + ': ' + str(tag_frame.clue_value.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bba180-d67f-4eaf-91df-3376650178b7",
   "metadata": {},
   "source": [
    "### Average Clue Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f8381-961b-4b6e-9623-57924d2c4a18",
   "metadata": {},
   "source": [
    "This looks at the average value of clues given the category labels I created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "52cd55c8-7095-4d49-97be-0e5c4dcd998e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1984\n",
       "1         1984\n",
       "2         1984\n",
       "3         1984\n",
       "4         1984\n",
       "          ... \n",
       "529418    2025\n",
       "529419    2025\n",
       "529420    2025\n",
       "529421    2025\n",
       "529422    2025\n",
       "Name: date, Length: 529423, dtype: int32"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwc_sql.date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "1728f194-5ee4-4b95-8a94-8ceefdaf3691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "      <th>question_modified</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jordan</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loch</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caspian sea</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INVENTIONS</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>radio</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529417</th>\n",
       "      <td>16-LETTER WORDS</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>counterclockwise</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529418</th>\n",
       "      <td>16-LETTER WORDS</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>quadricentennial</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529419</th>\n",
       "      <td>16-LETTER WORDS</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disqualification</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529420</th>\n",
       "      <td>16-LETTER WORDS</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>environmentalist</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529421</th>\n",
       "      <td>16-LETTER WORDS</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nonbiodegradable</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520380 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               category  round  clue_value    max_predict second_max_predict  \\\n",
       "0        LAKES & RIVERS      1         200      geography                NaN   \n",
       "1        LAKES & RIVERS      1         400      geography                NaN   \n",
       "2        LAKES & RIVERS      1         800      geography                NaN   \n",
       "3        LAKES & RIVERS      1        1000      geography                NaN   \n",
       "4            INVENTIONS      1         200        science                NaN   \n",
       "...                 ...    ...         ...            ...                ...   \n",
       "529417  16-LETTER WORDS      2         400  miscellaneous                NaN   \n",
       "529418  16-LETTER WORDS      2         800  miscellaneous                NaN   \n",
       "529419  16-LETTER WORDS      2        1200  miscellaneous                NaN   \n",
       "529420  16-LETTER WORDS      2        1600  miscellaneous                NaN   \n",
       "529421  16-LETTER WORDS      2        2000  miscellaneous                NaN   \n",
       "\n",
       "       question_modified       date  year  \n",
       "0                 jordan 1984-09-10  1984  \n",
       "1                   loch 1984-09-10  1984  \n",
       "2               missouri 1984-09-10  1984  \n",
       "3            caspian sea 1984-09-10  1984  \n",
       "4                  radio 1984-09-10  1984  \n",
       "...                  ...        ...   ...  \n",
       "529417  counterclockwise 2025-07-25  2025  \n",
       "529418  quadricentennial 2025-07-25  2025  \n",
       "529419  disqualification 2025-07-25  2025  \n",
       "529420  environmentalist 2025-07-25  2025  \n",
       "529421  nonbiodegradable 2025-07-25  2025  \n",
       "\n",
       "[520380 rows x 8 columns]"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_cats['date'] = pd.to_datetime(questions_with_cats['air_date'], format='%Y-%m-%d')\n",
    "qwc_sql = questions_with_cats[['category', 'round', 'clue_value', 'max_predict', 'second_max_predict', 'question_modified', 'date']]\n",
    "\n",
    "qwc_sql = qwc_sql[qwc_sql['round'] != 3]\n",
    "qwc_sql['clue_value'] = [i * 2 if j <= pd.Timestamp('2001-11-26') else i for i, j in zip(qwc_sql.clue_value, qwc_sql.date)]\n",
    "qwc_sql['year'] = qwc_sql.date.dt.year\n",
    "\n",
    "qwc_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "d90311a9-de8a-4ea1-b5d6-2e17d7a1285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art\n",
      "business\n",
      "civics\n",
      "classical music\n",
      "fashion\n",
      "film\n",
      "food\n",
      "geography\n",
      "history\n",
      "literature\n",
      "miscellaneous\n",
      "pop culture\n",
      "pop music\n",
      "religion\n",
      "science\n",
      "sports\n",
      "television\n",
      "theater\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decade</th>\n",
       "      <th>category</th>\n",
       "      <th>avg value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>art</td>\n",
       "      <td>978.310502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>art</td>\n",
       "      <td>1017.973231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>art</td>\n",
       "      <td>1000.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>art</td>\n",
       "      <td>1007.017544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>art</td>\n",
       "      <td>1009.708738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1990</td>\n",
       "      <td>theater</td>\n",
       "      <td>1064.240857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2000</td>\n",
       "      <td>theater</td>\n",
       "      <td>1012.591152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2010</td>\n",
       "      <td>theater</td>\n",
       "      <td>998.360656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2020</td>\n",
       "      <td>theater</td>\n",
       "      <td>986.387996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>overall</td>\n",
       "      <td>theater</td>\n",
       "      <td>1024.295628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      decade category    avg value\n",
       "0       1980      art   978.310502\n",
       "1       1990      art  1017.973231\n",
       "2       2000      art  1000.781250\n",
       "3       2010      art  1007.017544\n",
       "4       2020      art  1009.708738\n",
       "..       ...      ...          ...\n",
       "103     1990  theater  1064.240857\n",
       "104     2000  theater  1012.591152\n",
       "105     2010  theater   998.360656\n",
       "106     2020  theater   986.387996\n",
       "107  overall  theater  1024.295628\n",
       "\n",
       "[108 rows x 3 columns]"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clue_decade_value = pd.DataFrame(columns=['decade', 'category', 'avg value'])\n",
    "\n",
    "for tag in tags:\n",
    "    print(tag)\n",
    "    sqldf_tag = qwc_sql[(qwc_sql.max_predict == tag) | (qwc_sql.second_max_predict == tag)]\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        select \n",
    "        FLOOR(year / 10) * 10 as 'decade', avg(clue_value) as avg_value\n",
    "        from sqldf_tag\n",
    "        group by FLOOR(year / 10) * 10\n",
    "        union all\n",
    "        select\n",
    "        'overall' as 'decade', avg(clue_value) as avg_value\n",
    "        from sqldf_tag\n",
    "        \"\"\"\n",
    "    yy = sqldf(query)\n",
    "\n",
    "    for i in range(0, len(yy)):\n",
    "        row = {'decade': yy['decade'][i], 'category': tag, 'avg value': yy['avg_value'][i]}\n",
    "        clue_decade_value.loc[len(clue_decade_value)] = row\n",
    "\n",
    "clue_decade_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "ca79e423-4cf5-4e3e-93c0-dc9b4c07fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clue_decade_value.to_csv('clue_value_decade_12282025b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce581c1-0f43-420c-8652-f8540d2db4ed",
   "metadata": {},
   "source": [
    "### Board Category Correlations\n",
    "\n",
    "This is the basis for my claim that there is usually one pop category per round and one literature category per game - I looked at the assigned tags within each jeopardy and double jeopardy board and ran correlations, plus i just summed the number of \"sports,\" \"television,\" \"film,\" \"pop music,\" and \"pop culture\" tags within each round. I regret not splitting out Broadway from theater but based on my 2021-22 analysis where I I don't think that'd make a huge difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "cad5c25a-282e-420d-ab46-6b6404b79405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_date</th>\n",
       "      <th>encoding_art_1</th>\n",
       "      <th>encoding_art_2</th>\n",
       "      <th>encoding_business_1</th>\n",
       "      <th>encoding_business_2</th>\n",
       "      <th>encoding_civics_1</th>\n",
       "      <th>encoding_civics_2</th>\n",
       "      <th>encoding_classical music_1</th>\n",
       "      <th>encoding_classical music_2</th>\n",
       "      <th>encoding_fashion_1</th>\n",
       "      <th>...</th>\n",
       "      <th>encoding_religion_1</th>\n",
       "      <th>encoding_religion_2</th>\n",
       "      <th>encoding_science_1</th>\n",
       "      <th>encoding_science_2</th>\n",
       "      <th>encoding_sports_1</th>\n",
       "      <th>encoding_sports_2</th>\n",
       "      <th>encoding_television_1</th>\n",
       "      <th>encoding_television_2</th>\n",
       "      <th>encoding_theater_1</th>\n",
       "      <th>encoding_theater_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_date  encoding_art_1  encoding_art_2  encoding_business_1  \\\n",
       "0   1984-09-10           False           False                False   \n",
       "4   1984-09-10           False           False                False   \n",
       "13  1984-09-10           False           False                False   \n",
       "17  1984-09-10           False           False                False   \n",
       "22  1984-09-10           False           False                False   \n",
       "\n",
       "    encoding_business_2  encoding_civics_1  encoding_civics_2  \\\n",
       "0                 False              False              False   \n",
       "4                 False              False              False   \n",
       "13                False              False              False   \n",
       "17                False              False              False   \n",
       "22                False              False              False   \n",
       "\n",
       "    encoding_classical music_1  encoding_classical music_2  \\\n",
       "0                        False                       False   \n",
       "4                        False                       False   \n",
       "13                       False                       False   \n",
       "17                       False                       False   \n",
       "22                       False                       False   \n",
       "\n",
       "    encoding_fashion_1  ...  encoding_religion_1  encoding_religion_2  \\\n",
       "0                False  ...                False                False   \n",
       "4                False  ...                False                False   \n",
       "13               False  ...                False                False   \n",
       "17               False  ...                False                False   \n",
       "22               False  ...                False                 True   \n",
       "\n",
       "    encoding_science_1  encoding_science_2  encoding_sports_1  \\\n",
       "0                False               False              False   \n",
       "4                 True               False              False   \n",
       "13               False               False              False   \n",
       "17               False               False              False   \n",
       "22               False               False              False   \n",
       "\n",
       "    encoding_sports_2  encoding_television_1  encoding_television_2  \\\n",
       "0               False                  False                  False   \n",
       "4               False                  False                  False   \n",
       "13              False                  False                  False   \n",
       "17              False                  False                  False   \n",
       "22              False                  False                  False   \n",
       "\n",
       "    encoding_theater_1  encoding_theater_2  \n",
       "0                False               False  \n",
       "4                False               False  \n",
       "13               False               False  \n",
       "17               False               False  \n",
       "22               False               False  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_with_cats = pd.merge(j, category_tags, on='category')\n",
    "\n",
    "category_corr = questions_with_cats[questions_with_cats['round'] != 3][['air_date', 'category', 'round', 'max_predict', 'second_max_predict']]\n",
    "\n",
    "category_corr['encoding_1'] = category_corr['max_predict'] + '_' + category_corr['round'].astype(str)\n",
    "category_corr['encoding_2'] = category_corr['second_max_predict'] + '_' + category_corr['round'].astype(str)\n",
    "\n",
    "category_corr = category_corr[['air_date', 'encoding_1', 'encoding_2']].drop_duplicates()\n",
    "\n",
    "merge1 = category_corr[['air_date', 'encoding_1']]\n",
    "merge2 = category_corr[['air_date', 'encoding_2']]\n",
    "merge1.columns = ['air_date', 'encoding']\n",
    "merge2.columns = ['air_date', 'encoding']\n",
    "\n",
    "for_encoding = pd.concat([merge1, merge2])\n",
    "for_encoding = for_encoding[~for_encoding.encoding.isnull()]\n",
    "\n",
    "encoded = pd.get_dummies(for_encoding, columns = ['encoding'])\n",
    "\n",
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "2d85503a-1104-4ae4-b64b-ccf8bf2bb9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_date', 'encoding_art_1', 'encoding_art_2', 'encoding_business_1',\n",
       "       'encoding_business_2', 'encoding_civics_1', 'encoding_civics_2',\n",
       "       'encoding_classical music_1', 'encoding_classical music_2',\n",
       "       'encoding_fashion_1', 'encoding_fashion_2', 'encoding_film_1',\n",
       "       'encoding_film_2', 'encoding_food_1', 'encoding_food_2',\n",
       "       'encoding_geography_1', 'encoding_geography_2', 'encoding_history_1',\n",
       "       'encoding_history_2', 'encoding_literature_1', 'encoding_literature_2',\n",
       "       'encoding_miscellaneous_1', 'encoding_miscellaneous_2',\n",
       "       'encoding_pop culture_1', 'encoding_pop culture_2',\n",
       "       'encoding_pop music_1', 'encoding_pop music_2', 'encoding_religion_1',\n",
       "       'encoding_religion_2', 'encoding_science_1', 'encoding_science_2',\n",
       "       'encoding_sports_1', 'encoding_sports_2', 'encoding_television_1',\n",
       "       'encoding_television_2', 'encoding_theater_1', 'encoding_theater_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "1a6a27ca-dee9-42ae-8835-51c718c037d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.columns = ['air_date', 'art_1', 'art_2', 'business_1',\n",
    "       'business_2', 'civics_1', 'civics_2',\n",
    "       'classical music_1', 'classical music_2',\n",
    "       'fashion_1', 'fashion_2', 'film_1',\n",
    "       'film_2', 'food_1', 'food_2',\n",
    "       'geography_1', 'geography_2', 'history_1',\n",
    "       'history_2', 'literature_1', 'literature_2',\n",
    "       'miscellaneous_1', 'miscellaneous_2',\n",
    "       'pop culture_1', 'pop culture_2',\n",
    "       'pop music_1', 'pop music_2', 'religion_1',\n",
    "       'religion_2', 'science_1', 'science_2',\n",
    "       'sports_1', 'sports_2', 'television_1',\n",
    "       'television_2', 'theater_1', 'theater_2']\n",
    "\n",
    "less_date = ['art_1', 'art_2', 'business_1',\n",
    "       'business_2', 'civics_1', 'civics_2',\n",
    "       'classical music_1', 'classical music_2',\n",
    "       'fashion_1', 'fashion_2', 'film_1',\n",
    "       'film_2', 'food_1', 'food_2',\n",
    "       'geography_1', 'geography_2', 'history_1',\n",
    "       'history_2', 'literature_1', 'literature_2',\n",
    "       'miscellaneous_1', 'miscellaneous_2',\n",
    "       'pop culture_1', 'pop culture_2',\n",
    "       'pop music_1', 'pop music_2', 'religion_1',\n",
    "       'religion_2', 'science_1', 'science_2',\n",
    "       'sports_1', 'sports_2', 'television_1',\n",
    "       'television_2', 'theater_1', 'theater_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "991f6663-8d7d-4cee-af51-1784f7b311f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoded.groupby(by='air_date').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "35b2f243-e156-476b-b198-7665c3575290",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded['j_tags'] = encoded[['art_1', 'business_1', 'civics_1', 'classical music_1', 'fashion_1',  'film_1',\\\n",
    "                            'food_1', 'geography_1', 'history_1', 'literature_1', 'miscellaneous_1', 'pop culture_1', \\\n",
    "                             'pop music_1', 'religion_1','science_1', 'sports_1',  'television_1', 'theater_1']].sum(axis=1)\n",
    "encoded['dj_tags'] = encoded[['art_2', 'business_2', 'civics_2', 'classical music_2', 'fashion_2',  'film_2',\\\n",
    "                            'food_2', 'geography_2', 'history_2', 'literature_2', 'miscellaneous_2', 'pop culture_2', \\\n",
    "                             'pop music_2', 'religion_2','science_2', 'sports_2',  'television_2', 'theater_2']].sum(axis=1)\n",
    "\n",
    "encoded['pop_count_1'] =  encoded[['film_1', 'pop culture_1', 'pop music_1', 'sports_1', 'television_1']].sum(axis=1)\n",
    "encoded['pop_count_2'] =  encoded[['film_2', 'pop culture_2', 'pop music_2', 'sports_2', 'television_2']].sum(axis=1)\n",
    "\n",
    "encoded['pop1_normalized'] = (encoded.pop_count_1 / encoded.j_tags) * 6 #pop categories per round accounting for double-tagged cats\n",
    "encoded['pop2_normalized'] = (encoded.pop_count_2 / encoded.dj_tags) * 6\n",
    "\n",
    "\n",
    "encoded[['pop_count_1', 'pop_count_2', 'pop1_normalized', 'pop2_normalized']].to_csv('pop_count_12262025.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bee54f-809c-4cdd-bf27-b42fd9778389",
   "metadata": {},
   "source": [
    "1.25 \"pop\" categories per j board and 1.1 \"pop\" categories per dj board since 1-1-2016, probably a scooch higher because broadway is pop but shakespeare is not (and i did not include theater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "e802540d-9dd3-4589-8b14-cd1c7dffd4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.to_csv('encoded_12262025.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10d756-185f-4bb6-bd4d-e17066a9c32e",
   "metadata": {},
   "source": [
    "holy shit you are such a nerd are you still reading this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "e337bae6-0c73-468c-9044-02fc375d4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoded.drop(['pop_count_1', 'pop_count_2', 'pop_count_1', 'pop_count_2', 'pop1_normalized', 'pop2_normalized'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "b64978d1-95a5-4e46-afb6-9fa49e7fa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = encoded.corr()\n",
    "\n",
    "correlation_matrix.melt(ignore_index=False).reset_index().to_csv('corr_matrix_12262025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "feab83f8-c8a1-4cd1-aebd-4517ad5393cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>literature_2</td>\n",
       "      <td>literature_1</td>\n",
       "      <td>-0.309532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>film_2</td>\n",
       "      <td>film_1</td>\n",
       "      <td>-0.195468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>pop music_2</td>\n",
       "      <td>film_2</td>\n",
       "      <td>-0.188528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>television_1</td>\n",
       "      <td>film_1</td>\n",
       "      <td>-0.175503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>pop music_2</td>\n",
       "      <td>pop music_1</td>\n",
       "      <td>-0.168414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>geography_2</td>\n",
       "      <td>geography_1</td>\n",
       "      <td>-0.167109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>science_2</td>\n",
       "      <td>science_1</td>\n",
       "      <td>-0.165080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>television_1</td>\n",
       "      <td>pop music_1</td>\n",
       "      <td>-0.163793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>theater_2</td>\n",
       "      <td>literature_2</td>\n",
       "      <td>-0.162828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>television_1</td>\n",
       "      <td>sports_1</td>\n",
       "      <td>-0.143851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>sports_1</td>\n",
       "      <td>pop music_1</td>\n",
       "      <td>-0.143239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>pop music_1</td>\n",
       "      <td>film_1</td>\n",
       "      <td>-0.143228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>television_2</td>\n",
       "      <td>film_2</td>\n",
       "      <td>-0.141495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>sports_1</td>\n",
       "      <td>film_1</td>\n",
       "      <td>-0.137910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>television_2</td>\n",
       "      <td>pop music_2</td>\n",
       "      <td>-0.123601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>food_2</td>\n",
       "      <td>food_1</td>\n",
       "      <td>-0.122666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>science_1</td>\n",
       "      <td>history_1</td>\n",
       "      <td>-0.120646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>television_2</td>\n",
       "      <td>television_1</td>\n",
       "      <td>-0.120164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>theater_2</td>\n",
       "      <td>miscellaneous_2</td>\n",
       "      <td>-0.100909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>theater_2</td>\n",
       "      <td>pop music_2</td>\n",
       "      <td>-0.099823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>miscellaneous_2</td>\n",
       "      <td>history_2</td>\n",
       "      <td>-0.099697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>food_1</td>\n",
       "      <td>fashion_1</td>\n",
       "      <td>-0.099456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>literature_1</td>\n",
       "      <td>geography_1</td>\n",
       "      <td>-0.097852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>religion_1</td>\n",
       "      <td>literature_1</td>\n",
       "      <td>-0.096575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>science_1</td>\n",
       "      <td>literature_1</td>\n",
       "      <td>-0.095469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index         variable     value\n",
       "703      literature_2     literature_1 -0.309532\n",
       "391            film_2           film_1 -0.195468\n",
       "443       pop music_2           film_2 -0.188528\n",
       "412      television_1           film_1 -0.175503\n",
       "937       pop music_2      pop music_1 -0.168414\n",
       "547       geography_2      geography_1 -0.167109\n",
       "1093        science_2        science_1 -0.165080\n",
       "944      television_1      pop music_1 -0.163793\n",
       "757         theater_2     literature_2 -0.162828\n",
       "1172     television_1         sports_1 -0.143851\n",
       "942          sports_1      pop music_1 -0.143239\n",
       "404       pop music_1           film_1 -0.143228\n",
       "451      television_2           film_2 -0.141495\n",
       "410          sports_1           film_1 -0.137910\n",
       "983      television_2      pop music_2 -0.123601\n",
       "469            food_2           food_1 -0.122666\n",
       "636         science_1        history_1 -0.120646\n",
       "1249     television_2     television_1 -0.120164\n",
       "833         theater_2  miscellaneous_2 -0.100909\n",
       "985         theater_2      pop music_2 -0.099823\n",
       "667   miscellaneous_2        history_2 -0.099697\n",
       "316            food_1        fashion_1 -0.099456\n",
       "550      literature_1      geography_1 -0.097852\n",
       "710        religion_1     literature_1 -0.096575\n",
       "712         science_1     literature_1 -0.095469"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most strongly negatively correlated category-round combos. notable findings i probably didn't have space for in the article are \n",
    "# \"there will be probably not be another literature category\"\n",
    "# the way tv/pop music/film all avoid each other within the same round\n",
    "# the way sports categories also behave that way\n",
    "\n",
    "melted = correlation_matrix.melt(ignore_index=False).reset_index().drop_duplicates(subset=['value']).sort_values('value')\n",
    "\n",
    "melted[melted.value != 1].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e7e19-52ef-42d4-bc97-2ad2e9046bd9",
   "metadata": {},
   "source": [
    "### New Answerlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04ecba44-e4d1-46f4-b8e7-dc4da36867a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "      <th>question_modified</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jordan</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loch</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>missouri</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>geography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caspian sea</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INVENTIONS</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>radio</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category  round  clue_value max_predict second_max_predict  \\\n",
       "0  LAKES & RIVERS      1         100   geography                NaN   \n",
       "1  LAKES & RIVERS      1         200   geography                NaN   \n",
       "2  LAKES & RIVERS      1         400   geography                NaN   \n",
       "3  LAKES & RIVERS      1         500   geography                NaN   \n",
       "4      INVENTIONS      1         100     science                NaN   \n",
       "\n",
       "  question_modified       date  year  \n",
       "0            jordan 1984-09-10  1984  \n",
       "1              loch 1984-09-10  1984  \n",
       "2          missouri 1984-09-10  1984  \n",
       "3       caspian sea 1984-09-10  1984  \n",
       "4             radio 1984-09-10  1984  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_date = pd.Timestamp('2025-08-01')\n",
    "\n",
    "questions_with_cats['date'] = pd.to_datetime(questions_with_cats['air_date'], format='%Y-%m-%d')\n",
    "#questions_with_cats['time_since'] = (questions_with_cats.date - base_date).dt.days * -1\n",
    "\n",
    "questions_with_cats\n",
    "\n",
    "qwc_sql = questions_with_cats[['category', 'round', 'clue_value', 'max_predict', 'second_max_predict', 'question_modified', 'date']]\n",
    "\n",
    "qwc_sql['year'] = [i.year for i in qwc_sql['date']]\n",
    "\n",
    "qwc_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3821b0f2-37ae-4313-a124-f2d9dab74d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "      <th>question_modified</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415808</th>\n",
       "      <td>CASINO</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>crap table</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277105</th>\n",
       "      <td>SPORTS STARS</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sullivan award</td>\n",
       "      <td>2006-10-13</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473785</th>\n",
       "      <td>\\'80s LADIES</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vanity fair</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247676</th>\n",
       "      <td>WOMEN IN SPORTS</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nancy lieberman</td>\n",
       "      <td>2004-06-29</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399121</th>\n",
       "      <td>FAMILIAR SOUNDING TRIPLES</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop drop role</td>\n",
       "      <td>2015-11-11</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         category  round  clue_value max_predict  \\\n",
       "415808                     CASINO      2        2000      sports   \n",
       "277105               SPORTS STARS      2        2000      sports   \n",
       "473785               \\'80s LADIES      2        2000      sports   \n",
       "247676            WOMEN IN SPORTS      2        2000      sports   \n",
       "399121  FAMILIAR SOUNDING TRIPLES      2        2000      sports   \n",
       "\n",
       "       second_max_predict question_modified       date  year  \n",
       "415808                NaN        crap table 2017-02-01  2017  \n",
       "277105                NaN    sullivan award 2006-10-13  2006  \n",
       "473785                NaN       vanity fair 2021-07-27  2021  \n",
       "247676                NaN   nancy lieberman 2004-06-29  2004  \n",
       "399121                NaN    stop drop role 2015-11-11  2015  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwc_sql[(qwc_sql.max_predict == 'sports') & (qwc_sql.clue_value == 2000)].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba77be4b-5371-45a3-ab58-9da00b56c156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "      <th>question_modified</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>repeated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LET'S PLAY ALGEBRA!</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>science</td>\n",
       "      <td>None</td>\n",
       "      <td>0 0</td>\n",
       "      <td>2009-11-13 00:00:00.000000</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAMES PEOPLE PLAY</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>sports</td>\n",
       "      <td>None</td>\n",
       "      <td>0 00</td>\n",
       "      <td>2002-04-25 00:00:00.000000</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHANCE</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>None</td>\n",
       "      <td>0 00</td>\n",
       "      <td>2011-07-13 00:00:00.000000</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GREEN THINGS</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>science</td>\n",
       "      <td>None</td>\n",
       "      <td>0 00</td>\n",
       "      <td>2014-01-06 00:00:00.000000</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LET'S GAMBLE</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>sports</td>\n",
       "      <td>None</td>\n",
       "      <td>0 00</td>\n",
       "      <td>2022-05-16 00:00:00.000000</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522898</th>\n",
       "      <td>THE GERMAN UMLAUT</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>None</td>\n",
       "      <td>über</td>\n",
       "      <td>2018-11-26 00:00:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522899</th>\n",
       "      <td>DIËRESIS &amp; ÜMLAUT WÖRDS</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>None</td>\n",
       "      <td>über</td>\n",
       "      <td>2021-10-15 00:00:00.000000</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522900</th>\n",
       "      <td>IT'S GERMAN FOR...</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>None</td>\n",
       "      <td>übermensch</td>\n",
       "      <td>2023-04-28 00:00:00.000000</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522901</th>\n",
       "      <td>WORLD HISTORY</td>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>history</td>\n",
       "      <td>None</td>\n",
       "      <td>điện biên phủ</td>\n",
       "      <td>2024-07-17 00:00:00.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522902</th>\n",
       "      <td>MATH</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>science</td>\n",
       "      <td>None</td>\n",
       "      <td>πr2</td>\n",
       "      <td>1994-01-24 00:00:00.000000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522903 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       category  round  clue_value    max_predict  \\\n",
       "0           LET'S PLAY ALGEBRA!      2        1600        science   \n",
       "1             GAMES PEOPLE PLAY      2        1600         sports   \n",
       "2                        CHANCE      2         800  miscellaneous   \n",
       "3                  GREEN THINGS      1         800        science   \n",
       "4                  LET'S GAMBLE      2        1200         sports   \n",
       "...                         ...    ...         ...            ...   \n",
       "522898        THE GERMAN UMLAUT      1         600  miscellaneous   \n",
       "522899  DIËRESIS & ÜMLAUT WÖRDS      2         400  miscellaneous   \n",
       "522900       IT'S GERMAN FOR...      2        1600  miscellaneous   \n",
       "522901            WORLD HISTORY      2        1600        history   \n",
       "522902                     MATH      1         200        science   \n",
       "\n",
       "       second_max_predict question_modified                        date  year  \\\n",
       "0                    None               0 0  2009-11-13 00:00:00.000000  2009   \n",
       "1                    None              0 00  2002-04-25 00:00:00.000000  2002   \n",
       "2                    None              0 00  2011-07-13 00:00:00.000000  2011   \n",
       "3                    None              0 00  2014-01-06 00:00:00.000000  2014   \n",
       "4                    None              0 00  2022-05-16 00:00:00.000000  2022   \n",
       "...                   ...               ...                         ...   ...   \n",
       "522898               None              über  2018-11-26 00:00:00.000000  2018   \n",
       "522899               None              über  2021-10-15 00:00:00.000000  2021   \n",
       "522900               None        übermensch  2023-04-28 00:00:00.000000  2023   \n",
       "522901               None     điện biên phủ  2024-07-17 00:00:00.000000  2024   \n",
       "522902               None               πr2  1994-01-24 00:00:00.000000  1994   \n",
       "\n",
       "        repeated  \n",
       "0              1  \n",
       "1              1  \n",
       "2              2  \n",
       "3              3  \n",
       "4              4  \n",
       "...          ...  \n",
       "522898         2  \n",
       "522899         3  \n",
       "522900         1  \n",
       "522901         1  \n",
       "522902         1  \n",
       "\n",
       "[522903 rows x 9 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwc_sql_mod =qwc_sql[qwc_sql.question_modified.apply(lambda x: len(str(x))> 2)]\n",
    "\n",
    "query = \"\"\"\n",
    "select \n",
    "*, \n",
    "ROW_NUMBER() over (partition by question_modified order by date) as 'repeated'\n",
    "from\n",
    "qwc_sql_mod\n",
    "order by question_modified\n",
    "\"\"\"\n",
    "\n",
    "answer_repeat = sqldf(query) #.head(50) #.to_csv('art_check1.csv')\n",
    "\n",
    "answer_repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fca18d01-0bd6-446e-b649-551ec2d71d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art\n",
      "business\n",
      "civics\n",
      "classical music\n",
      "fashion\n",
      "film\n",
      "food\n",
      "geography\n",
      "history\n",
      "literature\n",
      "miscellaneous\n",
      "pop culture\n",
      "pop music\n",
      "religion\n",
      "science\n",
      "sports\n",
      "television\n",
      "theater\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>average</th>\n",
       "      <th>clue count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>33.137355</td>\n",
       "      <td>2155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>24.444110</td>\n",
       "      <td>3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>civics</td>\n",
       "      <td>31.040433</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical music</td>\n",
       "      <td>28.002859</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fashion</td>\n",
       "      <td>19.296477</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>film</td>\n",
       "      <td>20.571821</td>\n",
       "      <td>6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "      <td>23.902411</td>\n",
       "      <td>4355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>geography</td>\n",
       "      <td>57.738760</td>\n",
       "      <td>18416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>history</td>\n",
       "      <td>42.195220</td>\n",
       "      <td>21299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>literature</td>\n",
       "      <td>31.207896</td>\n",
       "      <td>12184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>15.776574</td>\n",
       "      <td>31845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>18.910489</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pop music</td>\n",
       "      <td>20.012531</td>\n",
       "      <td>6384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion</td>\n",
       "      <td>33.303734</td>\n",
       "      <td>2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>science</td>\n",
       "      <td>27.442071</td>\n",
       "      <td>15873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sports</td>\n",
       "      <td>24.403979</td>\n",
       "      <td>4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>television</td>\n",
       "      <td>18.390028</td>\n",
       "      <td>5315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theater</td>\n",
       "      <td>37.322296</td>\n",
       "      <td>3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category    average  clue count\n",
       "0               art  33.137355        2155\n",
       "1          business  24.444110        3650\n",
       "2            civics  31.040433        2770\n",
       "3   classical music  28.002859        1399\n",
       "4           fashion  19.296477        1022\n",
       "5              film  20.571821        6920\n",
       "6              food  23.902411        4355\n",
       "7         geography  57.738760       18416\n",
       "8           history  42.195220       21299\n",
       "9        literature  31.207896       12184\n",
       "10    miscellaneous  15.776574       31845\n",
       "11      pop culture  18.910489        2536\n",
       "12        pop music  20.012531        6384\n",
       "13         religion  33.303734        2973\n",
       "14          science  27.442071       15873\n",
       "15           sports  24.403979        4926\n",
       "16       television  18.390028        5315\n",
       "17          theater  37.322296        3292"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated = pd.DataFrame(columns=['category', 'average', 'clue count'])\n",
    "\n",
    "for tag in tags:\n",
    "    sqldf_tag = answer_repeat[(answer_repeat.max_predict == tag) | (answer_repeat.second_max_predict == tag)]\n",
    "    \n",
    "    query = \"\"\"\n",
    "    select \n",
    "    avg(repeated) as 'avg'\n",
    "    , count(*) as 'clues tagged'\n",
    "    from sqldf_tag\n",
    "    where date >= '2016-01-01'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(tag)\n",
    "    yy = sqldf(query)\n",
    "    \n",
    "    row = {'category': tag, 'average': yy['avg'][0], 'clue count': yy['clues tagged'][0]}\n",
    "    repeated.loc[len(repeated)] = row\n",
    "\n",
    "repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eede0fbf-2ffd-4d72-8c67-c8910802af2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>average</th>\n",
       "      <th>clue count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>geography</td>\n",
       "      <td>57.738760</td>\n",
       "      <td>18416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>history</td>\n",
       "      <td>42.195220</td>\n",
       "      <td>21299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theater</td>\n",
       "      <td>37.322296</td>\n",
       "      <td>3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion</td>\n",
       "      <td>33.303734</td>\n",
       "      <td>2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>33.137355</td>\n",
       "      <td>2155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>literature</td>\n",
       "      <td>31.207896</td>\n",
       "      <td>12184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>civics</td>\n",
       "      <td>31.040433</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical music</td>\n",
       "      <td>28.002859</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>science</td>\n",
       "      <td>27.442071</td>\n",
       "      <td>15873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>24.444110</td>\n",
       "      <td>3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sports</td>\n",
       "      <td>24.403979</td>\n",
       "      <td>4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "      <td>23.902411</td>\n",
       "      <td>4355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>film</td>\n",
       "      <td>20.571821</td>\n",
       "      <td>6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pop music</td>\n",
       "      <td>20.012531</td>\n",
       "      <td>6384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fashion</td>\n",
       "      <td>19.296477</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>18.910489</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>television</td>\n",
       "      <td>18.390028</td>\n",
       "      <td>5315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>15.776574</td>\n",
       "      <td>31845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category    average  clue count\n",
       "7         geography  57.738760       18416\n",
       "8           history  42.195220       21299\n",
       "17          theater  37.322296        3292\n",
       "13         religion  33.303734        2973\n",
       "0               art  33.137355        2155\n",
       "9        literature  31.207896       12184\n",
       "2            civics  31.040433        2770\n",
       "3   classical music  28.002859        1399\n",
       "14          science  27.442071       15873\n",
       "1          business  24.444110        3650\n",
       "15           sports  24.403979        4926\n",
       "6              food  23.902411        4355\n",
       "5              film  20.571821        6920\n",
       "12        pop music  20.012531        6384\n",
       "4           fashion  19.296477        1022\n",
       "11      pop culture  18.910489        2536\n",
       "16       television  18.390028        5315\n",
       "10    miscellaneous  15.776574       31845"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated.sort_values('average', ascending=False) # average number of times an answerline in this category has been used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84c66515-f7a9-4bf9-95c2-0eab34a7395f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_predict</th>\n",
       "      <th>avg(freq)</th>\n",
       "      <th>sum(debut)</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>37.287918</td>\n",
       "      <td>154</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>31.229155</td>\n",
       "      <td>514</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>civics</td>\n",
       "      <td>36.774484</td>\n",
       "      <td>274</td>\n",
       "      <td>1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical music</td>\n",
       "      <td>37.995301</td>\n",
       "      <td>135</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fashion</td>\n",
       "      <td>22.636986</td>\n",
       "      <td>135</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>film</td>\n",
       "      <td>35.630861</td>\n",
       "      <td>682</td>\n",
       "      <td>6526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "      <td>28.001511</td>\n",
       "      <td>539</td>\n",
       "      <td>3971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>geography</td>\n",
       "      <td>68.087452</td>\n",
       "      <td>1382</td>\n",
       "      <td>17541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>history</td>\n",
       "      <td>49.603870</td>\n",
       "      <td>1717</td>\n",
       "      <td>18706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>literature</td>\n",
       "      <td>44.892268</td>\n",
       "      <td>1049</td>\n",
       "      <td>11705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>31.951993</td>\n",
       "      <td>7438</td>\n",
       "      <td>35474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>24.031250</td>\n",
       "      <td>369</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pop music</td>\n",
       "      <td>29.154986</td>\n",
       "      <td>859</td>\n",
       "      <td>6007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion</td>\n",
       "      <td>44.379964</td>\n",
       "      <td>257</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>science</td>\n",
       "      <td>37.750017</td>\n",
       "      <td>1769</td>\n",
       "      <td>14773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sports</td>\n",
       "      <td>39.469410</td>\n",
       "      <td>601</td>\n",
       "      <td>4544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>television</td>\n",
       "      <td>26.352579</td>\n",
       "      <td>734</td>\n",
       "      <td>5040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theater</td>\n",
       "      <td>55.859613</td>\n",
       "      <td>193</td>\n",
       "      <td>2892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        max_predict  avg(freq)  sum(debut)  count(*)\n",
       "0               art  37.287918         154      1945\n",
       "1          business  31.229155         514      3430\n",
       "2            civics  36.774484         274      1889\n",
       "3   classical music  37.995301         135      1277\n",
       "4           fashion  22.636986         135      1022\n",
       "5              film  35.630861         682      6526\n",
       "6              food  28.001511         539      3971\n",
       "7         geography  68.087452        1382     17541\n",
       "8           history  49.603870        1717     18706\n",
       "9        literature  44.892268        1049     11705\n",
       "10    miscellaneous  31.951993        7438     35474\n",
       "11      pop culture  24.031250         369      2016\n",
       "12        pop music  29.154986         859      6007\n",
       "13         religion  44.379964         257      2795\n",
       "14          science  37.750017        1769     14773\n",
       "15           sports  39.469410         601      4544\n",
       "16       television  26.352579         734      5040\n",
       "17          theater  55.859613         193      2892"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwc_sql['year'] = [i.year for i in qwc_sql['date']]\n",
    "\n",
    "query = \"\"\"\n",
    "select \n",
    "qwc_sql.*\n",
    ", freq.freq\n",
    ", case when freq.debut_date = qwc_sql.date then 1 else 0 end as debut\n",
    "from \n",
    "qwc_sql\n",
    "left join (select \n",
    "question_modified,\n",
    "count(*) as freq, \n",
    "min(date) as debut_date\n",
    "from qwc_sql\n",
    "group by question_modified) freq\n",
    "on qwc_sql.question_modified = freq.question_modified\"\"\"\n",
    "\n",
    "answer_freq = sqldf(query) #.head(50) #.to_csv('art_check1.csv')\n",
    "\n",
    "answer_freq\n",
    "\n",
    "sqldf24 = answer_freq[(answer_freq.date > '2015-01-01')] #& (answer_freq.second_max_predict.isnull())]\n",
    "\n",
    "query = \"\"\"\n",
    "select max_predict, avg(freq), sum(debut), count(*)\n",
    "from sqldf24\n",
    "group by max_predict\"\"\"\n",
    "\n",
    "sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec7845b8-454d-4096-b358-cef94b6142ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art\n",
      "('charles mckim', 'agitprop', 'subway car', 'semiquincentennial', 'athens school', 'duck boat')\n",
      "business\n",
      "('touchtone dialing', 'express scripts', 'costvolumeprofit', 'barrel barrelhead', 'margin call', 'lillard')\n",
      "civics\n",
      "('lds faith mormon church', 'pump breast milk', 'small back', 'marriage story', 'nick kroll', 'chase manhattan')\n",
      "classical music\n",
      "('toucan wiccan', 'toot horn', 'j ogden armour', 'reel leer', 'shapenote singing', 'fire rome burned')\n",
      "fashion\n",
      "('jean jacket', 'christian siriano', 'brünhilde', 'smith college', 'aviator sunglass', 'outback hat')\n",
      "film\n",
      "('nathalie emmanuel', 'mike myers dana carvey', 'zack snyder', 'reefer madness', 'halloweentown', 'ephron')\n",
      "food\n",
      "('martha custis washington', 'bay leaf laurel leaf', 'lead lead', 'figgy pudding plum pudding', 'booze cruise', 'beth berth beth')\n",
      "geography\n",
      "('university tokyo', 'chain link fence', 'us steel tower', 'clemente', 'ossuary', 'upper new york bay')\n",
      "history\n",
      "('earl oxford edward de vere', 'war democrats', 'emperor rome', 'join nato', 'ambulance service', 'immortals')\n",
      "literature\n",
      "('murders morgue', 'courageous', 'hundred dalmatians 101 dalmatians', 'konstantin stanislavski', 'coy cozy', '911 commission')\n",
      "miscellaneous\n",
      "('lux et lex', 'dead stock', 'miniseries ministry', 'cocomelon', 'palpate', 'wobbly wobblies')\n",
      "pop culture\n",
      "('ford v ferrari', 'boss baby', 'charli damelio', 'furriest', 'ca breathe', 'gigi gigli')\n",
      "pop music\n",
      "('crank that', 'shadow night', 'pale fire', 'andy reid', 'paper planes', 'adam mckay')\n",
      "religion\n",
      "('new pope', 'mississippi hippie', 'citron etrog', 'aesculapius', 'book acts', 'arcadian stag')\n",
      "science\n",
      "('luteinizing hormone', 'pancreatic cancer', 'telomere', 'havanese', 'wicked wicked', 'hips')\n",
      "sports\n",
      "('full dance card', 'sue bird', 'curvy', 'cards humanity', 'miller schiller', '9volt battery')\n",
      "television\n",
      "('jenna ortega', 'forged fire', 'grace frankie', 'winterfell', 'encanto', 'sisi')\n",
      "theater\n",
      "('la donna', 'nerdfighters', 'suffs', 'spring breakers', 'donuts', 'veruca salt')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>new answerline</th>\n",
       "      <th>all clues</th>\n",
       "      <th>rate</th>\n",
       "      <th>examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>175</td>\n",
       "      <td>2157</td>\n",
       "      <td>0.081131</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>565</td>\n",
       "      <td>3704</td>\n",
       "      <td>0.152538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>civics</td>\n",
       "      <td>375</td>\n",
       "      <td>2798</td>\n",
       "      <td>0.134024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical music</td>\n",
       "      <td>155</td>\n",
       "      <td>1407</td>\n",
       "      <td>0.110163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fashion</td>\n",
       "      <td>137</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>film</td>\n",
       "      <td>741</td>\n",
       "      <td>6999</td>\n",
       "      <td>0.105872</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "      <td>607</td>\n",
       "      <td>4369</td>\n",
       "      <td>0.138933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>geography</td>\n",
       "      <td>1490</td>\n",
       "      <td>18487</td>\n",
       "      <td>0.080597</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>history</td>\n",
       "      <td>1993</td>\n",
       "      <td>21418</td>\n",
       "      <td>0.093053</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>literature</td>\n",
       "      <td>1130</td>\n",
       "      <td>12270</td>\n",
       "      <td>0.092095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>6709</td>\n",
       "      <td>32359</td>\n",
       "      <td>0.207330</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>422</td>\n",
       "      <td>2564</td>\n",
       "      <td>0.164587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pop music</td>\n",
       "      <td>921</td>\n",
       "      <td>6453</td>\n",
       "      <td>0.142724</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion</td>\n",
       "      <td>286</td>\n",
       "      <td>2998</td>\n",
       "      <td>0.095397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>science</td>\n",
       "      <td>1993</td>\n",
       "      <td>16016</td>\n",
       "      <td>0.124438</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sports</td>\n",
       "      <td>669</td>\n",
       "      <td>5002</td>\n",
       "      <td>0.133747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>television</td>\n",
       "      <td>801</td>\n",
       "      <td>5368</td>\n",
       "      <td>0.149218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theater</td>\n",
       "      <td>216</td>\n",
       "      <td>3308</td>\n",
       "      <td>0.065296</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  new answerline  all clues      rate  examples\n",
       "0               art             175       2157  0.081131       NaN\n",
       "1          business             565       3704  0.152538       NaN\n",
       "2            civics             375       2798  0.134024       NaN\n",
       "3   classical music             155       1407  0.110163       NaN\n",
       "4           fashion             137       1024  0.133789       NaN\n",
       "5              film             741       6999  0.105872       NaN\n",
       "6              food             607       4369  0.138933       NaN\n",
       "7         geography            1490      18487  0.080597       NaN\n",
       "8           history            1993      21418  0.093053       NaN\n",
       "9        literature            1130      12270  0.092095       NaN\n",
       "10    miscellaneous            6709      32359  0.207330       NaN\n",
       "11      pop culture             422       2564  0.164587       NaN\n",
       "12        pop music             921       6453  0.142724       NaN\n",
       "13         religion             286       2998  0.095397       NaN\n",
       "14          science            1993      16016  0.124438       NaN\n",
       "15           sports             669       5002  0.133747       NaN\n",
       "16       television             801       5368  0.149218       NaN\n",
       "17          theater             216       3308  0.065296       NaN"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debut_answer_rate = pd.DataFrame(columns=['category', 'new answerline', 'all clues', 'rate', 'examples'])\n",
    "\n",
    "for tag in tags:\n",
    "    sqldf_tag = answer_freq[(answer_freq.max_predict == tag) | (answer_freq.second_max_predict == tag)]\n",
    "    \n",
    "    query = \"\"\"\n",
    "    select sum(debut), count(*)\n",
    "    from sqldf_tag\n",
    "    where date >= '2016-01-01'\n",
    "    \"\"\"\n",
    "\n",
    "    debut_frame = sqldf_tag[(sqldf_tag.debut == 1) & (sqldf_tag.date >= '2020-01-01')]\n",
    "    debut_list = list(debut_frame.question_modified)\n",
    "\n",
    "    shuffle(debut_list)\n",
    "    trigrams = [t for t in zip(*[iter(debut_list)]*6)][:1]\n",
    "\n",
    "    print(tag)\n",
    "    print(*trigrams,sep=\"\\n\")\n",
    "\n",
    "    yy = sqldf(query)\n",
    "    \n",
    "    row = {'category': tag, 'new answerline': yy['sum(debut)'][0], 'all clues': yy['count(*)'][0], 'rate': yy['sum(debut)'][0] / yy['count(*)'][0]}\n",
    "    debut_answer_rate.loc[len(debut_answer_rate)] = row\n",
    "\n",
    "debut_answer_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "df6972bf-9f42-4078-b347-5f75bb04afd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>new answerline</th>\n",
       "      <th>all clues</th>\n",
       "      <th>rate</th>\n",
       "      <th>examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>6709</td>\n",
       "      <td>32359</td>\n",
       "      <td>0.207330</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>422</td>\n",
       "      <td>2564</td>\n",
       "      <td>0.164587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>565</td>\n",
       "      <td>3704</td>\n",
       "      <td>0.152538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>television</td>\n",
       "      <td>801</td>\n",
       "      <td>5368</td>\n",
       "      <td>0.149218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pop music</td>\n",
       "      <td>921</td>\n",
       "      <td>6453</td>\n",
       "      <td>0.142724</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "      <td>607</td>\n",
       "      <td>4369</td>\n",
       "      <td>0.138933</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>civics</td>\n",
       "      <td>375</td>\n",
       "      <td>2798</td>\n",
       "      <td>0.134024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fashion</td>\n",
       "      <td>137</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sports</td>\n",
       "      <td>669</td>\n",
       "      <td>5002</td>\n",
       "      <td>0.133747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>science</td>\n",
       "      <td>1993</td>\n",
       "      <td>16016</td>\n",
       "      <td>0.124438</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classical music</td>\n",
       "      <td>155</td>\n",
       "      <td>1407</td>\n",
       "      <td>0.110163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>film</td>\n",
       "      <td>741</td>\n",
       "      <td>6999</td>\n",
       "      <td>0.105872</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion</td>\n",
       "      <td>286</td>\n",
       "      <td>2998</td>\n",
       "      <td>0.095397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>history</td>\n",
       "      <td>1993</td>\n",
       "      <td>21418</td>\n",
       "      <td>0.093053</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>literature</td>\n",
       "      <td>1130</td>\n",
       "      <td>12270</td>\n",
       "      <td>0.092095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>175</td>\n",
       "      <td>2157</td>\n",
       "      <td>0.081131</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>geography</td>\n",
       "      <td>1490</td>\n",
       "      <td>18483</td>\n",
       "      <td>0.080615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>theater</td>\n",
       "      <td>216</td>\n",
       "      <td>3308</td>\n",
       "      <td>0.065296</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  new answerline  all clues      rate  examples\n",
       "10    miscellaneous            6709      32359  0.207330       NaN\n",
       "11      pop culture             422       2564  0.164587       NaN\n",
       "1          business             565       3704  0.152538       NaN\n",
       "16       television             801       5368  0.149218       NaN\n",
       "12        pop music             921       6453  0.142724       NaN\n",
       "6              food             607       4369  0.138933       NaN\n",
       "2            civics             375       2798  0.134024       NaN\n",
       "4           fashion             137       1024  0.133789       NaN\n",
       "15           sports             669       5002  0.133747       NaN\n",
       "14          science            1993      16016  0.124438       NaN\n",
       "3   classical music             155       1407  0.110163       NaN\n",
       "5              film             741       6999  0.105872       NaN\n",
       "13         religion             286       2998  0.095397       NaN\n",
       "8           history            1993      21418  0.093053       NaN\n",
       "9        literature            1130      12270  0.092095       NaN\n",
       "0               art             175       2157  0.081131       NaN\n",
       "7         geography            1490      18483  0.080615       NaN\n",
       "17          theater             216       3308  0.065296       NaN"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debut_answer_rate.sort_values('rate', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "3b6c84b2-a1d4-41d7-a989-00e0dc2e1c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>round</th>\n",
       "      <th>clue_value</th>\n",
       "      <th>max_predict</th>\n",
       "      <th>second_max_predict</th>\n",
       "      <th>question_modified</th>\n",
       "      <th>date</th>\n",
       "      <th>time_since</th>\n",
       "      <th>is_cat</th>\n",
       "      <th>year</th>\n",
       "      <th>freq</th>\n",
       "      <th>age_years</th>\n",
       "      <th>debut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524134</th>\n",
       "      <td>HAT TRICKS</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>fashion</td>\n",
       "      <td>None</td>\n",
       "      <td>outback hat</td>\n",
       "      <td>2025-03-26 00:00:00.000000</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350445</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529047</th>\n",
       "      <td>FABRICS &amp; MATERIALS</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>fashion</td>\n",
       "      <td>None</td>\n",
       "      <td>chennai</td>\n",
       "      <td>2025-07-17 00:00:00.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435746</th>\n",
       "      <td>THE FBI's 10 MOST WANTED LIST</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>sports</td>\n",
       "      <td>fashion</td>\n",
       "      <td>jail card</td>\n",
       "      <td>2018-07-10 00:00:00.000000</td>\n",
       "      <td>2579</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>7.060917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428366</th>\n",
       "      <td>IT'S RAINING \"MEN\\\"</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>fashion</td>\n",
       "      <td>specimen</td>\n",
       "      <td>2018-01-12 00:00:00.000000</td>\n",
       "      <td>2758</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>7.550992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483473</th>\n",
       "      <td>FASHION</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>fashion</td>\n",
       "      <td>None</td>\n",
       "      <td>athleisure</td>\n",
       "      <td>2022-04-12 00:00:00.000000</td>\n",
       "      <td>1207</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>3.304586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527740</th>\n",
       "      <td>CLOTHES TIME</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>fashion</td>\n",
       "      <td>None</td>\n",
       "      <td>bodycon</td>\n",
       "      <td>2025-06-18 00:00:00.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478592</th>\n",
       "      <td>FASHION</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>fashion</td>\n",
       "      <td>None</td>\n",
       "      <td>little white dress</td>\n",
       "      <td>2021-12-16 00:00:00.000000</td>\n",
       "      <td>1324</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>3.624914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439176</th>\n",
       "      <td>SCHOOL UNIFORMS</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>fashion</td>\n",
       "      <td>None</td>\n",
       "      <td>lands end</td>\n",
       "      <td>2018-11-12 00:00:00.000000</td>\n",
       "      <td>2454</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6.718686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484983</th>\n",
       "      <td>SCORING A \"T—D\\\"</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>fashion</td>\n",
       "      <td>timid</td>\n",
       "      <td>2022-05-17 00:00:00.000000</td>\n",
       "      <td>1172</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>3.003422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482975</th>\n",
       "      <td>FA\"SH\"ION</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>fashion</td>\n",
       "      <td>None</td>\n",
       "      <td>shantung</td>\n",
       "      <td>2022-03-30 00:00:00.000000</td>\n",
       "      <td>1220</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>3.340178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             category  round  clue_value    max_predict  \\\n",
       "524134                     HAT TRICKS      1         600        fashion   \n",
       "529047            FABRICS & MATERIALS      2        2000        fashion   \n",
       "435746  THE FBI's 10 MOST WANTED LIST      1         600         sports   \n",
       "428366            IT'S RAINING \"MEN\\\"      1         600  miscellaneous   \n",
       "483473                        FASHION      1        1000        fashion   \n",
       "527740                   CLOTHES TIME      1         800        fashion   \n",
       "478592                        FASHION      1         200        fashion   \n",
       "439176                SCHOOL UNIFORMS      1         800        fashion   \n",
       "484983               SCORING A \"T—D\\\"      2         800  miscellaneous   \n",
       "482975                      FA\"SH\"ION      2        2000        fashion   \n",
       "\n",
       "       second_max_predict   question_modified                        date  \\\n",
       "524134               None         outback hat  2025-03-26 00:00:00.000000   \n",
       "529047               None             chennai  2025-07-17 00:00:00.000000   \n",
       "435746            fashion           jail card  2018-07-10 00:00:00.000000   \n",
       "428366            fashion            specimen  2018-01-12 00:00:00.000000   \n",
       "483473               None          athleisure  2022-04-12 00:00:00.000000   \n",
       "527740               None             bodycon  2025-06-18 00:00:00.000000   \n",
       "478592               None  little white dress  2021-12-16 00:00:00.000000   \n",
       "439176               None           lands end  2018-11-12 00:00:00.000000   \n",
       "484983            fashion               timid  2022-05-17 00:00:00.000000   \n",
       "482975               None            shantung  2022-03-30 00:00:00.000000   \n",
       "\n",
       "        time_since  is_cat  year  freq  age_years  debut  \n",
       "524134         128       0  2025     1   0.350445      1  \n",
       "529047          15       0  2025     1   0.041068      1  \n",
       "435746        2579       0  2018     1   7.060917      1  \n",
       "428366        2758       0  2018     1   7.550992      1  \n",
       "483473        1207       0  2022     1   3.304586      1  \n",
       "527740          44       0  2025     1   0.120465      1  \n",
       "478592        1324       0  2021     1   3.624914      1  \n",
       "439176        2454       0  2018     1   6.718686      1  \n",
       "484983        1172       0  2022     2   3.003422      1  \n",
       "482975        1220       0  2022     1   3.340178      1  "
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sqldf24 = answer_freq[(answer_freq.date > '2016-01-01')] #& (answer_freq.second_max_predict.isnull())]\n",
    "\n",
    "for tag in ['fashion']:\n",
    "    sqldf_tag = answer_freq[(answer_freq.max_predict == tag) | (answer_freq.second_max_predict == tag)]\n",
    "    sqldf_tag = sqldf_tag[sqldf_tag.date >= '2016-01-01']\n",
    "    \n",
    "    query = \"\"\"\n",
    "    select sum(debut), count(*)    from sqldf_tag\"\"\"\n",
    "\n",
    "    yy = sqldf(query)\n",
    "\n",
    "sqldf_tag[sqldf_tag.debut == 1].sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
